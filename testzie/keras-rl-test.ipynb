{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rl.agents.dqn import *\n",
    "from rl.policy import *\n",
    "from rl.memory import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "env.seed(123)\n",
    "env.reset()\n",
    "action_num = env.action_space.n\n",
    "observe_shape = env.observation_space.shape\n",
    "window_length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_x = Input((window_length, )+observe_shape)\n",
    "model_y = Flatten()(model_x)\n",
    "model_y = Dense(16)(model_y)\n",
    "model_y = Dense(16)(model_y)\n",
    "model_y = Dense(16)(model_y)\n",
    "model_y = Dense(action_num)(model_y)\n",
    "model = Model(model_x, model_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=200000, window_length=window_length)\n",
    "policy = EpsGreedyQPolicy()\n",
    "dqn = DQNAgent(model=model, nb_actions=action_num, memory=memory, nb_steps_warmup=1000,\n",
    "               target_model_update=0.05, policy=policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dqn.compile(Adam(), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100000 steps ...\n",
      "   200/100000: episode: 1, duration: 0.570s, episode steps: 200, steps per second: 351, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.080 [0.000, 2.000], mean observation: -0.336 [-0.857, 0.015], loss: --, mean_squared_error: --, mean_q: --\n",
      "   400/100000: episode: 2, duration: 0.258s, episode steps: 200, steps per second: 775, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.135 [0.000, 2.000], mean observation: -0.322 [-0.700, 0.004], loss: --, mean_squared_error: --, mean_q: --\n",
      "   600/100000: episode: 3, duration: 0.257s, episode steps: 200, steps per second: 777, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.090 [0.000, 2.000], mean observation: -0.338 [-0.978, 0.023], loss: --, mean_squared_error: --, mean_q: --\n",
      "   800/100000: episode: 4, duration: 0.271s, episode steps: 200, steps per second: 737, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.100 [0.000, 2.000], mean observation: -0.327 [-0.752, 0.010], loss: --, mean_squared_error: --, mean_q: --\n",
      "  1000/100000: episode: 5, duration: 0.262s, episode steps: 200, steps per second: 762, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.080 [0.000, 2.000], mean observation: -0.335 [-0.870, 0.017], loss: --, mean_squared_error: --, mean_q: --\n",
      "  1200/100000: episode: 6, duration: 3.507s, episode steps: 200, steps per second: 57, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.890 [0.000, 2.000], mean observation: -0.261 [-1.200, 0.035], loss: 0.087200, mean_squared_error: 17.127114, mean_q: -4.268407\n",
      "  1400/100000: episode: 7, duration: 2.391s, episode steps: 200, steps per second: 84, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.580 [0.000, 2.000], mean observation: -0.300 [-0.924, 0.033], loss: 0.429790, mean_squared_error: 107.938194, mean_q: -12.249246\n",
      "  1600/100000: episode: 8, duration: 2.245s, episode steps: 200, steps per second: 89, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.860 [0.000, 2.000], mean observation: -0.279 [-0.889, 0.021], loss: 1.073126, mean_squared_error: 233.519257, mean_q: -18.243568\n",
      "  1800/100000: episode: 9, duration: 2.052s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.835 [0.000, 2.000], mean observation: -0.283 [-0.867, 0.034], loss: 1.955580, mean_squared_error: 395.415771, mean_q: -23.924910\n",
      "  2000/100000: episode: 10, duration: 2.313s, episode steps: 200, steps per second: 86, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.880 [0.000, 2.000], mean observation: -0.251 [-0.919, 0.035], loss: 1.889464, mean_squared_error: 590.051147, mean_q: -29.394899\n",
      "  2200/100000: episode: 11, duration: 2.182s, episode steps: 200, steps per second: 92, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.930 [0.000, 2.000], mean observation: -0.283 [-0.968, 0.034], loss: 2.235564, mean_squared_error: 803.563293, mean_q: -34.359161\n",
      "  2400/100000: episode: 12, duration: 2.075s, episode steps: 200, steps per second: 96, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.215 [0.000, 2.000], mean observation: -0.249 [-0.742, 0.028], loss: 4.391356, mean_squared_error: 954.780640, mean_q: -37.311047\n",
      "  2581/100000: episode: 13, duration: 1.844s, episode steps: 181, steps per second: 98, episode reward: -181.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.122 [0.000, 2.000], mean observation: -0.242 [-1.200, 0.524], loss: 4.166232, mean_squared_error: 1097.506226, mean_q: -40.171902\n",
      "  2781/100000: episode: 14, duration: 1.991s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.305 [0.000, 2.000], mean observation: -0.241 [-0.699, 0.013], loss: 4.916743, mean_squared_error: 1153.384521, mean_q: -41.244064\n",
      "  2981/100000: episode: 15, duration: 2.036s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.465 [0.000, 2.000], mean observation: -0.244 [-0.965, 0.048], loss: 3.180516, mean_squared_error: 1311.930420, mean_q: -44.006359\n",
      "  3181/100000: episode: 16, duration: 2.134s, episode steps: 200, steps per second: 94, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.865 [0.000, 2.000], mean observation: -0.290 [-1.068, 0.028], loss: 5.303185, mean_squared_error: 1460.247314, mean_q: -46.376434\n",
      "  3381/100000: episode: 17, duration: 2.023s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.085 [0.000, 2.000], mean observation: -0.233 [-0.902, 0.049], loss: 4.367435, mean_squared_error: 1583.812500, mean_q: -48.316971\n",
      "  3581/100000: episode: 18, duration: 2.080s, episode steps: 200, steps per second: 96, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.200 [0.000, 2.000], mean observation: -0.238 [-0.810, 0.027], loss: 5.861256, mean_squared_error: 1705.387207, mean_q: -50.080067\n",
      "  3781/100000: episode: 19, duration: 2.045s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.890 [0.000, 2.000], mean observation: -0.266 [-0.793, 0.027], loss: 7.216356, mean_squared_error: 1802.759888, mean_q: -51.437080\n",
      "  3981/100000: episode: 20, duration: 2.024s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.905 [0.000, 2.000], mean observation: -0.271 [-0.875, 0.039], loss: 8.751782, mean_squared_error: 1852.561523, mean_q: -52.089882\n",
      "  4181/100000: episode: 21, duration: 2.021s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.950 [0.000, 2.000], mean observation: -0.264 [-0.944, 0.062], loss: 4.462187, mean_squared_error: 1950.451294, mean_q: -53.618546\n",
      "  4381/100000: episode: 22, duration: 2.043s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.105 [0.000, 2.000], mean observation: -0.253 [-1.200, 0.206], loss: 7.504705, mean_squared_error: 2035.916748, mean_q: -54.545021\n",
      "  4581/100000: episode: 23, duration: 1.969s, episode steps: 200, steps per second: 102, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.740 [0.000, 2.000], mean observation: -0.282 [-0.786, 0.028], loss: 7.718209, mean_squared_error: 2134.907227, mean_q: -55.920250\n",
      "  4781/100000: episode: 24, duration: 2.044s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.575 [0.000, 2.000], mean observation: -0.324 [-1.111, 0.035], loss: 9.060929, mean_squared_error: 2126.767578, mean_q: -55.687916\n",
      "  4981/100000: episode: 25, duration: 1.998s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.825 [0.000, 2.000], mean observation: -0.284 [-1.186, 0.322], loss: 6.481713, mean_squared_error: 2163.149414, mean_q: -56.254894\n",
      "  5181/100000: episode: 26, duration: 2.104s, episode steps: 200, steps per second: 95, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.725 [0.000, 2.000], mean observation: -0.282 [-0.741, 0.023], loss: 8.548053, mean_squared_error: 2196.858398, mean_q: -56.719765\n",
      "  5381/100000: episode: 27, duration: 2.075s, episode steps: 200, steps per second: 96, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.435 [0.000, 2.000], mean observation: -0.339 [-1.169, 0.041], loss: 8.523642, mean_squared_error: 2198.146484, mean_q: -56.696354\n",
      "  5581/100000: episode: 28, duration: 2.052s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.790 [0.000, 2.000], mean observation: -0.291 [-0.908, 0.029], loss: 8.791718, mean_squared_error: 2220.304443, mean_q: -57.047901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5781/100000: episode: 29, duration: 2.009s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.770 [0.000, 2.000], mean observation: -0.281 [-0.855, 0.036], loss: 9.633472, mean_squared_error: 2207.810059, mean_q: -56.815933\n",
      "  5981/100000: episode: 30, duration: 2.022s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.670 [0.000, 2.000], mean observation: -0.286 [-0.752, 0.027], loss: 8.459774, mean_squared_error: 2252.182861, mean_q: -57.488346\n",
      "  6181/100000: episode: 31, duration: 2.016s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.400 [0.000, 2.000], mean observation: -0.333 [-1.200, 0.042], loss: 7.678733, mean_squared_error: 2246.707275, mean_q: -57.385670\n",
      "  6381/100000: episode: 32, duration: 2.022s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.430 [0.000, 2.000], mean observation: -0.307 [-0.886, 0.021], loss: 9.273962, mean_squared_error: 2240.537598, mean_q: -57.395252\n",
      "  6581/100000: episode: 33, duration: 2.013s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.570 [0.000, 2.000], mean observation: -0.308 [-1.036, 0.033], loss: 5.669099, mean_squared_error: 2250.054932, mean_q: -57.639462\n",
      "  6781/100000: episode: 34, duration: 1.990s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.345 [0.000, 2.000], mean observation: -0.317 [-0.924, 0.027], loss: 6.361538, mean_squared_error: 2341.354492, mean_q: -58.780342\n",
      "  6981/100000: episode: 35, duration: 2.033s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.870 [0.000, 2.000], mean observation: -0.266 [-0.829, 0.033], loss: 8.672718, mean_squared_error: 2369.857666, mean_q: -59.070057\n",
      "  7181/100000: episode: 36, duration: 1.996s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.455 [0.000, 2.000], mean observation: -0.311 [-1.023, 0.028], loss: 8.820783, mean_squared_error: 2365.946777, mean_q: -59.019131\n",
      "  7381/100000: episode: 37, duration: 2.036s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.635 [0.000, 2.000], mean observation: -0.293 [-0.970, 0.033], loss: 8.412124, mean_squared_error: 2360.932861, mean_q: -58.932743\n",
      "  7581/100000: episode: 38, duration: 2.009s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.655 [0.000, 2.000], mean observation: -0.291 [-0.855, 0.019], loss: 6.288287, mean_squared_error: 2391.549316, mean_q: -59.433361\n",
      "  7781/100000: episode: 39, duration: 2.051s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.720 [0.000, 2.000], mean observation: -0.291 [-0.833, 0.030], loss: 10.284380, mean_squared_error: 2420.146484, mean_q: -59.669628\n",
      "  7981/100000: episode: 40, duration: 2.045s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.150 [0.000, 2.000], mean observation: -0.251 [-1.015, 0.037], loss: 9.813560, mean_squared_error: 2369.942871, mean_q: -59.022850\n",
      "  8156/100000: episode: 41, duration: 1.755s, episode steps: 175, steps per second: 100, episode reward: -175.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.000 [0.000, 2.000], mean observation: -0.251 [-1.200, 0.512], loss: 9.789982, mean_squared_error: 2368.625244, mean_q: -59.014915\n",
      "  8356/100000: episode: 42, duration: 2.005s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.755 [0.000, 2.000], mean observation: -0.274 [-0.753, 0.017], loss: 9.770078, mean_squared_error: 2317.971436, mean_q: -58.434250\n",
      "  8556/100000: episode: 43, duration: 2.001s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.800 [0.000, 2.000], mean observation: -0.295 [-1.200, 0.048], loss: 5.934793, mean_squared_error: 2379.306396, mean_q: -59.312366\n",
      "  8756/100000: episode: 44, duration: 2.023s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.855 [0.000, 2.000], mean observation: -0.283 [-0.972, 0.028], loss: 9.350285, mean_squared_error: 2432.236084, mean_q: -59.870285\n",
      "  8956/100000: episode: 45, duration: 2.007s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.795 [0.000, 2.000], mean observation: -0.284 [-0.833, 0.028], loss: 9.581272, mean_squared_error: 2430.345459, mean_q: -59.840633\n",
      "  9156/100000: episode: 46, duration: 2.022s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.765 [0.000, 2.000], mean observation: -0.286 [-0.862, 0.020], loss: 11.006892, mean_squared_error: 2386.757080, mean_q: -59.099197\n",
      "  9356/100000: episode: 47, duration: 2.000s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.820 [0.000, 2.000], mean observation: -0.269 [-0.851, 0.022], loss: 5.666589, mean_squared_error: 2404.602783, mean_q: -59.624191\n",
      "  9556/100000: episode: 48, duration: 2.007s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.730 [0.000, 2.000], mean observation: -0.280 [-0.952, 0.031], loss: 8.278554, mean_squared_error: 2472.003662, mean_q: -60.468605\n",
      "  9756/100000: episode: 49, duration: 1.991s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.615 [0.000, 2.000], mean observation: -0.286 [-0.787, 0.027], loss: 10.274806, mean_squared_error: 2437.541992, mean_q: -59.871006\n",
      "  9956/100000: episode: 50, duration: 2.004s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.735 [0.000, 2.000], mean observation: -0.274 [-0.991, 0.037], loss: 11.193982, mean_squared_error: 2445.563965, mean_q: -60.082767\n",
      " 10156/100000: episode: 51, duration: 2.016s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.645 [0.000, 2.000], mean observation: -0.271 [-0.768, 0.027], loss: 9.373724, mean_squared_error: 2404.263428, mean_q: -59.480942\n",
      " 10356/100000: episode: 52, duration: 2.007s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.900 [0.000, 2.000], mean observation: -0.274 [-0.773, 0.018], loss: 7.289954, mean_squared_error: 2363.209717, mean_q: -59.062122\n",
      " 10556/100000: episode: 53, duration: 2.013s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.030 [0.000, 2.000], mean observation: -0.261 [-0.951, 0.013], loss: 8.833604, mean_squared_error: 2388.048340, mean_q: -59.436756\n",
      " 10756/100000: episode: 54, duration: 2.023s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.820 [0.000, 2.000], mean observation: -0.281 [-0.834, 0.031], loss: 10.461636, mean_squared_error: 2368.795898, mean_q: -59.137276\n",
      " 10956/100000: episode: 55, duration: 2.004s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.075 [0.000, 2.000], mean observation: -0.276 [-1.062, 0.023], loss: 6.387829, mean_squared_error: 2420.051514, mean_q: -59.871738\n",
      " 11156/100000: episode: 56, duration: 2.036s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.805 [0.000, 2.000], mean observation: -0.269 [-0.928, 0.041], loss: 10.565448, mean_squared_error: 2430.558838, mean_q: -59.868927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11356/100000: episode: 57, duration: 2.054s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.990 [0.000, 2.000], mean observation: -0.268 [-0.773, 0.032], loss: 10.229617, mean_squared_error: 2314.282471, mean_q: -58.439907\n",
      " 11556/100000: episode: 58, duration: 2.039s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.670 [0.000, 2.000], mean observation: -0.298 [-0.966, 0.032], loss: 9.023934, mean_squared_error: 2312.299561, mean_q: -58.470272\n",
      " 11756/100000: episode: 59, duration: 2.013s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.805 [0.000, 2.000], mean observation: -0.281 [-0.942, 0.025], loss: 9.749804, mean_squared_error: 2287.154541, mean_q: -58.093117\n",
      " 11956/100000: episode: 60, duration: 2.051s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.850 [0.000, 2.000], mean observation: -0.265 [-0.714, 0.024], loss: 8.449787, mean_squared_error: 2249.481934, mean_q: -57.667233\n",
      " 12156/100000: episode: 61, duration: 2.034s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.620 [0.000, 2.000], mean observation: -0.291 [-0.734, 0.017], loss: 10.108356, mean_squared_error: 2260.840332, mean_q: -57.730370\n",
      " 12356/100000: episode: 62, duration: 2.011s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.015 [0.000, 2.000], mean observation: -0.255 [-0.783, 0.022], loss: 8.410806, mean_squared_error: 2200.204346, mean_q: -56.986446\n",
      " 12556/100000: episode: 63, duration: 2.022s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.945 [0.000, 2.000], mean observation: -0.261 [-1.077, 0.070], loss: 10.149692, mean_squared_error: 2162.981934, mean_q: -56.500233\n",
      " 12756/100000: episode: 64, duration: 2.028s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.010 [0.000, 2.000], mean observation: -0.262 [-1.200, 0.119], loss: 8.701328, mean_squared_error: 2139.789062, mean_q: -56.306046\n",
      " 12956/100000: episode: 65, duration: 2.016s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.795 [0.000, 2.000], mean observation: -0.290 [-1.014, 0.022], loss: 8.819319, mean_squared_error: 2161.089111, mean_q: -56.486782\n",
      " 13156/100000: episode: 66, duration: 2.009s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.045 [0.000, 2.000], mean observation: -0.282 [-1.200, 0.040], loss: 6.164050, mean_squared_error: 2167.256348, mean_q: -56.655392\n",
      " 13356/100000: episode: 67, duration: 2.015s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.705 [0.000, 2.000], mean observation: -0.297 [-0.924, 0.033], loss: 8.462791, mean_squared_error: 2229.243896, mean_q: -57.537315\n",
      " 13556/100000: episode: 68, duration: 2.014s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.005 [0.000, 2.000], mean observation: -0.262 [-0.885, 0.017], loss: 8.123885, mean_squared_error: 2243.650391, mean_q: -57.634483\n",
      " 13756/100000: episode: 69, duration: 2.003s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.075 [0.000, 2.000], mean observation: -0.243 [-1.119, 0.206], loss: 8.865901, mean_squared_error: 2255.167725, mean_q: -57.751728\n",
      " 13956/100000: episode: 70, duration: 2.027s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.815 [0.000, 2.000], mean observation: -0.277 [-0.906, 0.038], loss: 8.584415, mean_squared_error: 2253.262695, mean_q: -57.716888\n",
      " 14156/100000: episode: 71, duration: 2.013s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.875 [0.000, 2.000], mean observation: -0.280 [-0.907, 0.027], loss: 10.588412, mean_squared_error: 2232.765625, mean_q: -57.427071\n",
      " 14356/100000: episode: 72, duration: 1.995s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.930 [0.000, 2.000], mean observation: -0.281 [-1.145, 0.040], loss: 6.965415, mean_squared_error: 2238.720215, mean_q: -57.553501\n",
      " 14556/100000: episode: 73, duration: 1.999s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.080 [0.000, 2.000], mean observation: -0.262 [-0.743, 0.027], loss: 9.862350, mean_squared_error: 2232.273682, mean_q: -57.388329\n",
      " 14756/100000: episode: 74, duration: 2.030s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.915 [0.000, 2.000], mean observation: -0.268 [-1.200, 0.183], loss: 6.920409, mean_squared_error: 2248.247803, mean_q: -57.688999\n",
      " 14956/100000: episode: 75, duration: 2.004s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.850 [0.000, 2.000], mean observation: -0.296 [-1.200, 0.097], loss: 6.491183, mean_squared_error: 2304.301025, mean_q: -58.373280\n",
      " 15156/100000: episode: 76, duration: 2.022s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.820 [0.000, 2.000], mean observation: -0.277 [-0.767, 0.021], loss: 6.956417, mean_squared_error: 2338.208740, mean_q: -58.915451\n",
      " 15356/100000: episode: 77, duration: 2.008s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.925 [0.000, 2.000], mean observation: -0.262 [-0.769, 0.021], loss: 8.825617, mean_squared_error: 2338.900635, mean_q: -58.811874\n",
      " 15556/100000: episode: 78, duration: 2.002s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.275 [0.000, 2.000], mean observation: -0.249 [-0.747, 0.021], loss: 8.540565, mean_squared_error: 2330.072754, mean_q: -58.611626\n",
      " 15756/100000: episode: 79, duration: 2.006s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.915 [0.000, 2.000], mean observation: -0.262 [-0.773, 0.031], loss: 8.361632, mean_squared_error: 2274.671631, mean_q: -58.068867\n",
      " 15956/100000: episode: 80, duration: 2.008s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.875 [0.000, 2.000], mean observation: -0.276 [-1.200, 0.123], loss: 6.167527, mean_squared_error: 2316.896973, mean_q: -58.572861\n",
      " 16156/100000: episode: 81, duration: 1.979s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.735 [0.000, 2.000], mean observation: -0.278 [-0.865, 0.027], loss: 10.495703, mean_squared_error: 2333.358398, mean_q: -58.668751\n",
      " 16356/100000: episode: 82, duration: 2.032s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.870 [0.000, 2.000], mean observation: -0.274 [-0.827, 0.016], loss: 8.901315, mean_squared_error: 2307.695068, mean_q: -58.427296\n",
      " 16556/100000: episode: 83, duration: 1.996s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.090 [0.000, 2.000], mean observation: -0.280 [-1.147, 0.043], loss: 6.890986, mean_squared_error: 2315.047119, mean_q: -58.559532\n",
      " 16756/100000: episode: 84, duration: 2.012s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.770 [0.000, 2.000], mean observation: -0.272 [-0.867, 0.025], loss: 8.336275, mean_squared_error: 2324.717285, mean_q: -58.585674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16956/100000: episode: 85, duration: 2.027s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.760 [0.000, 2.000], mean observation: -0.288 [-0.814, 0.020], loss: 6.422278, mean_squared_error: 2362.807861, mean_q: -59.183693\n",
      " 17156/100000: episode: 86, duration: 2.082s, episode steps: 200, steps per second: 96, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.855 [0.000, 2.000], mean observation: -0.294 [-1.058, 0.039], loss: 9.758695, mean_squared_error: 2364.176514, mean_q: -59.113007\n",
      " 17356/100000: episode: 87, duration: 2.107s, episode steps: 200, steps per second: 95, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.825 [0.000, 2.000], mean observation: -0.272 [-0.772, 0.016], loss: 8.818423, mean_squared_error: 2302.399414, mean_q: -58.313183\n",
      " 17556/100000: episode: 88, duration: 2.033s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.900 [0.000, 2.000], mean observation: -0.264 [-0.708, 0.017], loss: 7.575366, mean_squared_error: 2374.058105, mean_q: -59.353340\n",
      " 17756/100000: episode: 89, duration: 1.994s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.665 [0.000, 2.000], mean observation: -0.299 [-0.935, 0.037], loss: 11.384229, mean_squared_error: 2356.964600, mean_q: -59.017159\n",
      " 17956/100000: episode: 90, duration: 1.989s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.200 [0.000, 2.000], mean observation: -0.217 [-0.910, 0.127], loss: 9.072746, mean_squared_error: 2268.907471, mean_q: -57.813652\n",
      " 18156/100000: episode: 91, duration: 2.046s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.980 [0.000, 2.000], mean observation: -0.276 [-1.190, 0.022], loss: 10.118965, mean_squared_error: 2200.359131, mean_q: -57.016762\n",
      " 18356/100000: episode: 92, duration: 2.021s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.070 [0.000, 2.000], mean observation: -0.248 [-0.779, 0.023], loss: 9.857593, mean_squared_error: 2108.269775, mean_q: -55.749393\n",
      " 18556/100000: episode: 93, duration: 2.039s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.810 [0.000, 2.000], mean observation: -0.274 [-0.756, 0.030], loss: 9.586785, mean_squared_error: 2053.663574, mean_q: -54.990932\n",
      " 18756/100000: episode: 94, duration: 2.043s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.835 [0.000, 2.000], mean observation: -0.300 [-1.192, 0.046], loss: 7.015679, mean_squared_error: 2096.368164, mean_q: -55.710777\n",
      " 18956/100000: episode: 95, duration: 2.016s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.295 [0.000, 2.000], mean observation: -0.248 [-0.790, 0.023], loss: 7.654534, mean_squared_error: 2130.571045, mean_q: -56.157539\n",
      " 19156/100000: episode: 96, duration: 2.035s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.125 [0.000, 2.000], mean observation: -0.250 [-0.660, 0.013], loss: 9.086893, mean_squared_error: 2108.129883, mean_q: -55.701202\n",
      " 19356/100000: episode: 97, duration: 2.015s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.895 [0.000, 2.000], mean observation: -0.267 [-0.799, 0.021], loss: 6.687213, mean_squared_error: 2119.950195, mean_q: -56.030045\n",
      " 19556/100000: episode: 98, duration: 1.999s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.295 [0.000, 2.000], mean observation: -0.246 [-0.863, 0.026], loss: 7.497369, mean_squared_error: 2144.727783, mean_q: -56.245651\n",
      " 19756/100000: episode: 99, duration: 2.042s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.900 [0.000, 2.000], mean observation: -0.269 [-0.950, 0.035], loss: 9.232582, mean_squared_error: 2172.510986, mean_q: -56.577705\n",
      " 19956/100000: episode: 100, duration: 2.028s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.685 [0.000, 2.000], mean observation: -0.287 [-0.815, 0.034], loss: 10.252332, mean_squared_error: 2155.770264, mean_q: -56.330185\n",
      " 20156/100000: episode: 101, duration: 2.017s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.700 [0.000, 2.000], mean observation: -0.286 [-1.200, 0.051], loss: 6.505682, mean_squared_error: 2120.461426, mean_q: -55.974430\n",
      " 20356/100000: episode: 102, duration: 2.010s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.870 [0.000, 2.000], mean observation: -0.253 [-0.871, 0.036], loss: 8.058257, mean_squared_error: 2159.122314, mean_q: -56.415009\n",
      " 20556/100000: episode: 103, duration: 2.029s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.755 [0.000, 2.000], mean observation: -0.310 [-1.200, 0.052], loss: 6.298253, mean_squared_error: 2185.735107, mean_q: -56.766739\n",
      " 20756/100000: episode: 104, duration: 2.020s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.805 [0.000, 2.000], mean observation: -0.251 [-1.059, 0.183], loss: 6.197941, mean_squared_error: 2244.485596, mean_q: -57.596485\n",
      " 20956/100000: episode: 105, duration: 2.061s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.105 [0.000, 2.000], mean observation: -0.260 [-0.861, 0.027], loss: 7.101135, mean_squared_error: 2301.185059, mean_q: -58.254131\n",
      " 21156/100000: episode: 106, duration: 2.012s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.855 [0.000, 2.000], mean observation: -0.271 [-0.905, 0.029], loss: 8.292583, mean_squared_error: 2322.521484, mean_q: -58.594345\n",
      " 21356/100000: episode: 107, duration: 2.021s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.860 [0.000, 2.000], mean observation: -0.258 [-0.867, 0.035], loss: 5.827279, mean_squared_error: 2350.370361, mean_q: -58.962826\n",
      " 21556/100000: episode: 108, duration: 2.035s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.645 [0.000, 2.000], mean observation: -0.287 [-0.887, 0.030], loss: 8.905063, mean_squared_error: 2366.043213, mean_q: -59.130341\n",
      " 21756/100000: episode: 109, duration: 2.068s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.835 [0.000, 2.000], mean observation: -0.305 [-1.133, 0.058], loss: 9.890767, mean_squared_error: 2358.991455, mean_q: -59.013180\n",
      " 21956/100000: episode: 110, duration: 2.029s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.855 [0.000, 2.000], mean observation: -0.283 [-0.966, 0.031], loss: 9.172078, mean_squared_error: 2289.095459, mean_q: -58.098656\n",
      " 22156/100000: episode: 111, duration: 2.018s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.000 [0.000, 2.000], mean observation: -0.263 [-1.200, 0.130], loss: 8.178689, mean_squared_error: 2313.743896, mean_q: -58.452377\n",
      " 22356/100000: episode: 112, duration: 2.013s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.095 [0.000, 2.000], mean observation: -0.265 [-0.763, 0.030], loss: 10.249951, mean_squared_error: 2313.083008, mean_q: -58.453487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22556/100000: episode: 113, duration: 1.994s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.740 [0.000, 2.000], mean observation: -0.303 [-1.200, 0.049], loss: 8.535691, mean_squared_error: 2297.746582, mean_q: -58.177258\n",
      " 22756/100000: episode: 114, duration: 1.995s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.880 [0.000, 2.000], mean observation: -0.286 [-1.041, 0.030], loss: 7.893160, mean_squared_error: 2283.447266, mean_q: -58.085159\n",
      " 22956/100000: episode: 115, duration: 2.018s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.020 [0.000, 2.000], mean observation: -0.250 [-0.785, 0.022], loss: 10.438267, mean_squared_error: 2256.556152, mean_q: -57.728565\n",
      " 23156/100000: episode: 116, duration: 2.066s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.725 [0.000, 2.000], mean observation: -0.288 [-1.032, 0.034], loss: 7.682061, mean_squared_error: 2268.160645, mean_q: -57.845169\n",
      " 23356/100000: episode: 117, duration: 2.015s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.295 [0.000, 2.000], mean observation: -0.230 [-0.776, 0.032], loss: 10.332958, mean_squared_error: 2172.895996, mean_q: -56.577579\n",
      " 23556/100000: episode: 118, duration: 2.032s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.045 [0.000, 2.000], mean observation: -0.284 [-1.151, 0.047], loss: 7.264927, mean_squared_error: 2202.328613, mean_q: -57.080334\n",
      " 23756/100000: episode: 119, duration: 2.062s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.845 [0.000, 2.000], mean observation: -0.270 [-0.792, 0.023], loss: 8.241578, mean_squared_error: 2211.138184, mean_q: -57.192139\n",
      " 23956/100000: episode: 120, duration: 2.023s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.020 [0.000, 2.000], mean observation: -0.269 [-0.871, 0.040], loss: 6.365663, mean_squared_error: 2271.946777, mean_q: -58.049404\n",
      " 24156/100000: episode: 121, duration: 2.002s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.910 [0.000, 2.000], mean observation: -0.248 [-1.075, 0.093], loss: 8.550153, mean_squared_error: 2251.128174, mean_q: -57.585430\n",
      " 24356/100000: episode: 122, duration: 2.039s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.630 [0.000, 2.000], mean observation: -0.275 [-1.200, 0.045], loss: 9.909457, mean_squared_error: 2229.408203, mean_q: -57.364521\n",
      " 24556/100000: episode: 123, duration: 2.048s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.710 [0.000, 2.000], mean observation: -0.311 [-1.187, 0.035], loss: 7.840822, mean_squared_error: 2227.909180, mean_q: -57.394520\n",
      " 24756/100000: episode: 124, duration: 2.035s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.855 [0.000, 2.000], mean observation: -0.261 [-0.799, 0.032], loss: 8.175704, mean_squared_error: 2277.592529, mean_q: -58.127010\n",
      " 24956/100000: episode: 125, duration: 2.011s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.085 [0.000, 2.000], mean observation: -0.249 [-0.741, 0.030], loss: 6.494584, mean_squared_error: 2326.875977, mean_q: -58.689823\n",
      " 25156/100000: episode: 126, duration: 2.017s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.720 [0.000, 2.000], mean observation: -0.296 [-1.088, 0.022], loss: 6.105453, mean_squared_error: 2379.896973, mean_q: -59.346542\n",
      " 25356/100000: episode: 127, duration: 2.012s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.665 [0.000, 2.000], mean observation: -0.282 [-0.875, 0.024], loss: 11.496690, mean_squared_error: 2342.809570, mean_q: -58.824345\n",
      " 25556/100000: episode: 128, duration: 2.023s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.840 [0.000, 2.000], mean observation: -0.287 [-1.062, 0.050], loss: 10.206080, mean_squared_error: 2229.941650, mean_q: -57.298500\n",
      " 25756/100000: episode: 129, duration: 2.007s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.145 [0.000, 2.000], mean observation: -0.253 [-0.627, 0.010], loss: 8.723847, mean_squared_error: 2238.617676, mean_q: -57.585461\n",
      " 25956/100000: episode: 130, duration: 2.013s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.015 [0.000, 2.000], mean observation: -0.261 [-0.838, 0.029], loss: 10.184810, mean_squared_error: 2212.806641, mean_q: -57.243771\n",
      " 26156/100000: episode: 131, duration: 2.035s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.875 [0.000, 2.000], mean observation: -0.271 [-0.856, 0.030], loss: 8.322713, mean_squared_error: 2194.469971, mean_q: -57.003563\n",
      " 26356/100000: episode: 132, duration: 2.025s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.985 [0.000, 2.000], mean observation: -0.276 [-1.010, 0.040], loss: 9.678242, mean_squared_error: 2241.640381, mean_q: -57.570854\n",
      " 26556/100000: episode: 133, duration: 2.022s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.810 [0.000, 2.000], mean observation: -0.271 [-0.794, 0.024], loss: 10.187501, mean_squared_error: 2237.862549, mean_q: -57.558891\n",
      " 26756/100000: episode: 134, duration: 2.037s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.975 [0.000, 2.000], mean observation: -0.277 [-1.030, 0.043], loss: 10.273037, mean_squared_error: 2186.751465, mean_q: -56.727772\n",
      " 26956/100000: episode: 135, duration: 2.004s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.985 [0.000, 2.000], mean observation: -0.273 [-0.875, 0.019], loss: 7.370137, mean_squared_error: 2168.884766, mean_q: -56.706192\n",
      " 27156/100000: episode: 136, duration: 2.032s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.165 [0.000, 2.000], mean observation: -0.255 [-0.784, 0.028], loss: 7.178130, mean_squared_error: 2212.149414, mean_q: -57.280975\n",
      " 27356/100000: episode: 137, duration: 1.999s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.055 [0.000, 2.000], mean observation: -0.249 [-0.954, 0.045], loss: 9.478586, mean_squared_error: 2205.259033, mean_q: -57.063828\n",
      " 27556/100000: episode: 138, duration: 2.006s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.785 [0.000, 2.000], mean observation: -0.274 [-0.759, 0.022], loss: 10.913980, mean_squared_error: 2152.086670, mean_q: -56.434952\n",
      " 27756/100000: episode: 139, duration: 2.047s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.960 [0.000, 2.000], mean observation: -0.256 [-1.200, 0.048], loss: 9.517004, mean_squared_error: 2136.527588, mean_q: -56.117908\n",
      " 27956/100000: episode: 140, duration: 1.999s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.830 [0.000, 2.000], mean observation: -0.283 [-0.758, 0.029], loss: 7.840548, mean_squared_error: 2137.972412, mean_q: -56.241379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28156/100000: episode: 141, duration: 1.999s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.290 [0.000, 2.000], mean observation: -0.249 [-1.038, 0.026], loss: 8.121136, mean_squared_error: 2129.552246, mean_q: -56.094765\n",
      " 28356/100000: episode: 142, duration: 2.016s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.780 [0.000, 2.000], mean observation: -0.277 [-0.784, 0.021], loss: 8.675707, mean_squared_error: 2134.185791, mean_q: -56.146950\n",
      " 28556/100000: episode: 143, duration: 1.988s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.860 [0.000, 2.000], mean observation: -0.273 [-0.699, 0.020], loss: 8.111657, mean_squared_error: 2136.413086, mean_q: -56.295761\n",
      " 28756/100000: episode: 144, duration: 2.007s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.985 [0.000, 2.000], mean observation: -0.266 [-0.882, 0.030], loss: 6.878554, mean_squared_error: 2201.107178, mean_q: -57.126087\n",
      " 28956/100000: episode: 145, duration: 2.095s, episode steps: 200, steps per second: 95, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.915 [0.000, 2.000], mean observation: -0.283 [-0.954, 0.030], loss: 8.719828, mean_squared_error: 2186.379883, mean_q: -56.849133\n",
      " 29156/100000: episode: 146, duration: 2.055s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.010 [0.000, 2.000], mean observation: -0.269 [-0.922, 0.027], loss: 10.324059, mean_squared_error: 2140.650879, mean_q: -56.150753\n",
      " 29356/100000: episode: 147, duration: 2.001s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.865 [0.000, 2.000], mean observation: -0.267 [-0.754, 0.023], loss: 9.160748, mean_squared_error: 2129.663330, mean_q: -56.110138\n",
      " 29556/100000: episode: 148, duration: 2.019s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.750 [0.000, 2.000], mean observation: -0.285 [-1.044, 0.038], loss: 8.035025, mean_squared_error: 2155.017334, mean_q: -56.379326\n",
      " 29756/100000: episode: 149, duration: 2.045s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.620 [0.000, 2.000], mean observation: -0.289 [-0.765, 0.025], loss: 8.258856, mean_squared_error: 2162.870361, mean_q: -56.449272\n",
      " 29956/100000: episode: 150, duration: 1.994s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.870 [0.000, 2.000], mean observation: -0.275 [-0.845, 0.028], loss: 7.378473, mean_squared_error: 2166.373047, mean_q: -56.579464\n",
      " 30156/100000: episode: 151, duration: 2.005s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.775 [0.000, 2.000], mean observation: -0.254 [-1.080, 0.117], loss: 9.281580, mean_squared_error: 2190.124756, mean_q: -56.710987\n",
      " 30356/100000: episode: 152, duration: 2.032s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.890 [0.000, 2.000], mean observation: -0.258 [-0.892, 0.026], loss: 8.543761, mean_squared_error: 2214.965088, mean_q: -57.203739\n",
      " 30556/100000: episode: 153, duration: 2.027s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.705 [0.000, 2.000], mean observation: -0.272 [-0.706, 0.025], loss: 10.359287, mean_squared_error: 2204.176514, mean_q: -57.006317\n",
      " 30756/100000: episode: 154, duration: 1.990s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.815 [0.000, 2.000], mean observation: -0.297 [-1.200, 0.048], loss: 8.720022, mean_squared_error: 2150.227539, mean_q: -56.271748\n",
      " 30956/100000: episode: 155, duration: 2.033s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.895 [0.000, 2.000], mean observation: -0.261 [-0.948, 0.041], loss: 7.274920, mean_squared_error: 2157.495605, mean_q: -56.473915\n",
      " 31156/100000: episode: 156, duration: 2.042s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.750 [0.000, 2.000], mean observation: -0.274 [-1.200, 0.050], loss: 8.236396, mean_squared_error: 2206.049316, mean_q: -57.128036\n",
      " 31356/100000: episode: 157, duration: 2.041s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.100 [0.000, 2.000], mean observation: -0.267 [-0.952, 0.040], loss: 7.799711, mean_squared_error: 2235.172363, mean_q: -57.491035\n",
      " 31556/100000: episode: 158, duration: 2.004s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.790 [0.000, 2.000], mean observation: -0.271 [-0.873, 0.029], loss: 10.384787, mean_squared_error: 2251.552490, mean_q: -57.676704\n",
      " 31756/100000: episode: 159, duration: 2.027s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.855 [0.000, 2.000], mean observation: -0.285 [-0.912, 0.028], loss: 7.597998, mean_squared_error: 2273.986816, mean_q: -58.059662\n",
      " 31956/100000: episode: 160, duration: 2.031s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.105 [0.000, 2.000], mean observation: -0.252 [-0.836, 0.026], loss: 10.774488, mean_squared_error: 2234.823730, mean_q: -57.445091\n",
      " 32156/100000: episode: 161, duration: 2.055s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.070 [0.000, 2.000], mean observation: -0.264 [-0.846, 0.025], loss: 9.093537, mean_squared_error: 2181.233887, mean_q: -56.770321\n",
      " 32356/100000: episode: 162, duration: 2.018s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.825 [0.000, 2.000], mean observation: -0.301 [-1.045, 0.045], loss: 7.474545, mean_squared_error: 2225.032715, mean_q: -57.440044\n",
      " 32556/100000: episode: 163, duration: 2.038s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.815 [0.000, 2.000], mean observation: -0.272 [-1.051, 0.039], loss: 7.842523, mean_squared_error: 2273.305908, mean_q: -58.015778\n",
      " 32756/100000: episode: 164, duration: 2.017s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.045 [0.000, 2.000], mean observation: -0.255 [-0.815, 0.029], loss: 6.602496, mean_squared_error: 2283.663574, mean_q: -58.179344\n",
      " 32956/100000: episode: 165, duration: 2.037s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.990 [0.000, 2.000], mean observation: -0.263 [-1.026, 0.039], loss: 7.337973, mean_squared_error: 2353.779785, mean_q: -59.076466\n",
      " 33156/100000: episode: 166, duration: 2.029s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.865 [0.000, 2.000], mean observation: -0.269 [-0.771, 0.021], loss: 5.770157, mean_squared_error: 2404.055420, mean_q: -59.786797\n",
      " 33356/100000: episode: 167, duration: 2.048s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.960 [0.000, 2.000], mean observation: -0.266 [-0.797, 0.020], loss: 8.110239, mean_squared_error: 2433.080322, mean_q: -60.003342\n",
      " 33556/100000: episode: 168, duration: 2.032s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.765 [0.000, 2.000], mean observation: -0.276 [-0.898, 0.031], loss: 9.209772, mean_squared_error: 2424.741943, mean_q: -59.782959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33756/100000: episode: 169, duration: 2.024s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.330 [0.000, 2.000], mean observation: -0.222 [-0.919, 0.036], loss: 10.152372, mean_squared_error: 2355.977295, mean_q: -58.891685\n",
      " 33956/100000: episode: 170, duration: 2.041s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.010 [0.000, 2.000], mean observation: -0.266 [-0.779, 0.023], loss: 10.063325, mean_squared_error: 2315.597168, mean_q: -58.528587\n",
      " 34156/100000: episode: 171, duration: 2.009s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.095 [0.000, 2.000], mean observation: -0.250 [-0.758, 0.021], loss: 8.049807, mean_squared_error: 2258.192383, mean_q: -57.756187\n",
      " 34356/100000: episode: 172, duration: 2.041s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.325 [0.000, 2.000], mean observation: -0.229 [-0.769, 0.031], loss: 7.156712, mean_squared_error: 2252.556152, mean_q: -57.760197\n",
      " 34556/100000: episode: 173, duration: 2.035s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.850 [0.000, 2.000], mean observation: -0.262 [-0.848, 0.025], loss: 7.433634, mean_squared_error: 2311.610840, mean_q: -58.534321\n",
      " 34756/100000: episode: 174, duration: 2.030s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.220 [0.000, 2.000], mean observation: -0.247 [-0.859, 0.033], loss: 9.101738, mean_squared_error: 2331.881348, mean_q: -58.744770\n",
      " 34956/100000: episode: 175, duration: 2.031s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.335 [0.000, 2.000], mean observation: -0.247 [-0.883, 0.028], loss: 10.896521, mean_squared_error: 2275.144043, mean_q: -57.984318\n",
      " 35156/100000: episode: 176, duration: 2.042s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.760 [0.000, 2.000], mean observation: -0.299 [-1.009, 0.040], loss: 10.614900, mean_squared_error: 2221.728516, mean_q: -57.273563\n",
      " 35356/100000: episode: 177, duration: 2.026s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.215 [0.000, 2.000], mean observation: -0.254 [-0.747, 0.025], loss: 9.770960, mean_squared_error: 2208.802979, mean_q: -57.183239\n",
      " 35556/100000: episode: 178, duration: 2.015s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.905 [0.000, 2.000], mean observation: -0.261 [-0.890, 0.036], loss: 7.773634, mean_squared_error: 2237.640625, mean_q: -57.531307\n",
      " 35756/100000: episode: 179, duration: 2.045s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.955 [0.000, 2.000], mean observation: -0.271 [-0.979, 0.039], loss: 7.636575, mean_squared_error: 2276.074951, mean_q: -57.981258\n",
      " 35956/100000: episode: 180, duration: 2.048s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.880 [0.000, 2.000], mean observation: -0.265 [-0.754, 0.022], loss: 9.376318, mean_squared_error: 2286.309814, mean_q: -58.070362\n",
      " 36156/100000: episode: 181, duration: 2.037s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.705 [0.000, 2.000], mean observation: -0.287 [-0.884, 0.035], loss: 6.437167, mean_squared_error: 2298.124023, mean_q: -58.313000\n",
      " 36356/100000: episode: 182, duration: 2.021s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.950 [0.000, 2.000], mean observation: -0.276 [-1.036, 0.038], loss: 9.245035, mean_squared_error: 2335.052002, mean_q: -58.743053\n",
      " 36556/100000: episode: 183, duration: 1.953s, episode steps: 200, steps per second: 102, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.825 [0.000, 2.000], mean observation: -0.261 [-0.837, 0.030], loss: 9.031100, mean_squared_error: 2303.701172, mean_q: -58.335766\n",
      " 36756/100000: episode: 184, duration: 2.027s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.100 [0.000, 2.000], mean observation: -0.264 [-0.871, 0.034], loss: 8.479249, mean_squared_error: 2330.504150, mean_q: -58.703789\n",
      " 36956/100000: episode: 185, duration: 2.020s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.870 [0.000, 2.000], mean observation: -0.272 [-0.786, 0.020], loss: 10.183537, mean_squared_error: 2324.022461, mean_q: -58.606827\n",
      " 37156/100000: episode: 186, duration: 2.047s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.980 [0.000, 2.000], mean observation: -0.266 [-1.200, 0.193], loss: 8.843440, mean_squared_error: 2311.410400, mean_q: -58.441387\n",
      " 37356/100000: episode: 187, duration: 2.012s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.070 [0.000, 2.000], mean observation: -0.261 [-0.835, 0.034], loss: 7.234113, mean_squared_error: 2296.765381, mean_q: -58.362255\n",
      " 37556/100000: episode: 188, duration: 2.000s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.870 [0.000, 2.000], mean observation: -0.290 [-0.945, 0.032], loss: 6.088377, mean_squared_error: 2326.030273, mean_q: -58.704201\n",
      " 37756/100000: episode: 189, duration: 2.012s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.080 [0.000, 2.000], mean observation: -0.271 [-0.874, 0.039], loss: 7.841605, mean_squared_error: 2386.616699, mean_q: -59.485401\n",
      " 37956/100000: episode: 190, duration: 2.047s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.025 [0.000, 2.000], mean observation: -0.268 [-0.725, 0.026], loss: 7.216396, mean_squared_error: 2429.975830, mean_q: -59.966866\n",
      " 38156/100000: episode: 191, duration: 2.003s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.105 [0.000, 2.000], mean observation: -0.264 [-0.879, 0.028], loss: 9.875912, mean_squared_error: 2428.057861, mean_q: -59.873993\n",
      " 38356/100000: episode: 192, duration: 2.071s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.000 [0.000, 2.000], mean observation: -0.271 [-1.200, 0.031], loss: 8.783440, mean_squared_error: 2454.768066, mean_q: -60.217022\n",
      " 38556/100000: episode: 193, duration: 2.003s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.860 [0.000, 2.000], mean observation: -0.277 [-0.799, 0.021], loss: 9.490475, mean_squared_error: 2416.057617, mean_q: -59.816444\n",
      " 38756/100000: episode: 194, duration: 2.005s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.930 [0.000, 2.000], mean observation: -0.272 [-1.185, 0.049], loss: 10.242354, mean_squared_error: 2448.856934, mean_q: -60.264877\n",
      " 38956/100000: episode: 195, duration: 2.020s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.000 [0.000, 2.000], mean observation: -0.257 [-1.129, 0.151], loss: 7.909440, mean_squared_error: 2407.166260, mean_q: -59.682480\n",
      " 39156/100000: episode: 196, duration: 2.042s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.740 [0.000, 2.000], mean observation: -0.292 [-0.849, 0.033], loss: 9.362323, mean_squared_error: 2345.761475, mean_q: -58.912498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 39356/100000: episode: 197, duration: 2.011s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.870 [0.000, 2.000], mean observation: -0.258 [-0.943, 0.045], loss: 8.564527, mean_squared_error: 2344.207764, mean_q: -58.874393\n",
      " 39556/100000: episode: 198, duration: 2.000s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.080 [0.000, 2.000], mean observation: -0.245 [-1.017, 0.221], loss: 6.144185, mean_squared_error: 2410.752441, mean_q: -59.829239\n",
      " 39756/100000: episode: 199, duration: 2.007s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.010 [0.000, 2.000], mean observation: -0.247 [-1.200, 0.346], loss: 9.311605, mean_squared_error: 2436.407715, mean_q: -59.932785\n",
      " 39956/100000: episode: 200, duration: 2.057s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.785 [0.000, 2.000], mean observation: -0.254 [-0.958, 0.040], loss: 10.161507, mean_squared_error: 2362.466309, mean_q: -59.054306\n",
      " 40156/100000: episode: 201, duration: 2.000s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.945 [0.000, 2.000], mean observation: -0.269 [-0.939, 0.033], loss: 7.306450, mean_squared_error: 2337.174316, mean_q: -58.796906\n",
      " 40356/100000: episode: 202, duration: 2.041s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.805 [0.000, 2.000], mean observation: -0.291 [-1.016, 0.027], loss: 9.036734, mean_squared_error: 2381.424561, mean_q: -59.367340\n",
      " 40556/100000: episode: 203, duration: 2.007s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.160 [0.000, 2.000], mean observation: -0.236 [-0.937, 0.162], loss: 9.109461, mean_squared_error: 2375.573486, mean_q: -59.279179\n",
      " 40756/100000: episode: 204, duration: 2.096s, episode steps: 200, steps per second: 95, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.115 [0.000, 2.000], mean observation: -0.254 [-0.843, 0.023], loss: 6.249540, mean_squared_error: 2359.594971, mean_q: -59.149502\n",
      " 40956/100000: episode: 205, duration: 2.075s, episode steps: 200, steps per second: 96, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.240 [0.000, 2.000], mean observation: -0.238 [-0.744, 0.023], loss: 7.794092, mean_squared_error: 2406.784424, mean_q: -59.734512\n",
      " 41156/100000: episode: 206, duration: 2.020s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.050 [0.000, 2.000], mean observation: -0.262 [-0.794, 0.024], loss: 10.721985, mean_squared_error: 2389.740234, mean_q: -59.416935\n",
      " 41356/100000: episode: 207, duration: 2.011s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.140 [0.000, 2.000], mean observation: -0.260 [-0.771, 0.031], loss: 9.536749, mean_squared_error: 2356.392090, mean_q: -59.064686\n",
      " 41556/100000: episode: 208, duration: 2.010s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.785 [0.000, 2.000], mean observation: -0.269 [-0.682, 0.011], loss: 8.694584, mean_squared_error: 2338.020264, mean_q: -58.828827\n",
      " 41756/100000: episode: 209, duration: 2.011s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.145 [0.000, 2.000], mean observation: -0.251 [-0.795, 0.024], loss: 6.828784, mean_squared_error: 2371.985107, mean_q: -59.230499\n",
      " 41956/100000: episode: 210, duration: 2.046s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.835 [0.000, 2.000], mean observation: -0.297 [-1.200, 0.047], loss: 9.046863, mean_squared_error: 2380.148438, mean_q: -59.293007\n",
      " 42156/100000: episode: 211, duration: 2.005s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.910 [0.000, 2.000], mean observation: -0.257 [-0.805, 0.030], loss: 8.188200, mean_squared_error: 2387.439453, mean_q: -59.532120\n",
      " 42356/100000: episode: 212, duration: 1.988s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.950 [0.000, 2.000], mean observation: -0.265 [-0.711, 0.015], loss: 7.945066, mean_squared_error: 2456.093994, mean_q: -60.340321\n",
      " 42556/100000: episode: 213, duration: 1.982s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.985 [0.000, 2.000], mean observation: -0.260 [-0.818, 0.036], loss: 9.865493, mean_squared_error: 2454.288818, mean_q: -60.223125\n",
      " 42756/100000: episode: 214, duration: 1.972s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.075 [0.000, 2.000], mean observation: -0.245 [-0.777, 0.026], loss: 10.408308, mean_squared_error: 2394.749023, mean_q: -59.526279\n",
      " 42956/100000: episode: 215, duration: 2.038s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.400 [0.000, 2.000], mean observation: -0.228 [-1.023, 0.217], loss: 10.408023, mean_squared_error: 2312.999756, mean_q: -58.410206\n",
      " 43156/100000: episode: 216, duration: 2.024s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.945 [0.000, 2.000], mean observation: -0.272 [-0.826, 0.017], loss: 6.440600, mean_squared_error: 2314.778076, mean_q: -58.592842\n",
      " 43356/100000: episode: 217, duration: 2.037s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.150 [0.000, 2.000], mean observation: -0.249 [-0.767, 0.030], loss: 6.384151, mean_squared_error: 2398.541992, mean_q: -59.686314\n",
      " 43556/100000: episode: 218, duration: 1.981s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.850 [0.000, 2.000], mean observation: -0.263 [-1.178, 0.053], loss: 10.091757, mean_squared_error: 2434.422119, mean_q: -60.050751\n",
      " 43756/100000: episode: 219, duration: 2.023s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.790 [0.000, 2.000], mean observation: -0.256 [-0.971, 0.067], loss: 9.245782, mean_squared_error: 2409.929932, mean_q: -59.699337\n",
      " 43956/100000: episode: 220, duration: 2.038s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.885 [0.000, 2.000], mean observation: -0.266 [-0.752, 0.026], loss: 8.032777, mean_squared_error: 2410.940430, mean_q: -59.740898\n",
      " 44156/100000: episode: 221, duration: 2.020s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.360 [0.000, 2.000], mean observation: -0.245 [-0.802, 0.035], loss: 7.462542, mean_squared_error: 2388.827393, mean_q: -59.481632\n",
      " 44356/100000: episode: 222, duration: 2.035s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.915 [0.000, 2.000], mean observation: -0.279 [-0.802, 0.024], loss: 9.838973, mean_squared_error: 2394.113037, mean_q: -59.510361\n",
      " 44556/100000: episode: 223, duration: 1.994s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.035 [0.000, 2.000], mean observation: -0.278 [-0.972, 0.045], loss: 11.810195, mean_squared_error: 2312.206543, mean_q: -58.418945\n",
      " 44756/100000: episode: 224, duration: 2.016s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.715 [0.000, 2.000], mean observation: -0.277 [-0.901, 0.030], loss: 5.184320, mean_squared_error: 2325.531982, mean_q: -58.738583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44956/100000: episode: 225, duration: 2.017s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.995 [0.000, 2.000], mean observation: -0.268 [-1.054, 0.229], loss: 8.263647, mean_squared_error: 2406.404053, mean_q: -59.661621\n",
      " 45156/100000: episode: 226, duration: 2.025s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.860 [0.000, 2.000], mean observation: -0.263 [-1.151, 0.050], loss: 8.603748, mean_squared_error: 2404.125000, mean_q: -59.624947\n",
      " 45356/100000: episode: 227, duration: 2.016s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.880 [0.000, 2.000], mean observation: -0.271 [-0.938, 0.042], loss: 7.026758, mean_squared_error: 2436.347900, mean_q: -60.087646\n",
      " 45556/100000: episode: 228, duration: 2.008s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.910 [0.000, 2.000], mean observation: -0.269 [-0.747, 0.021], loss: 6.777928, mean_squared_error: 2488.594238, mean_q: -60.745617\n",
      " 45756/100000: episode: 229, duration: 1.993s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.045 [0.000, 2.000], mean observation: -0.232 [-1.109, 0.223], loss: 8.976333, mean_squared_error: 2510.166504, mean_q: -60.967789\n",
      " 45956/100000: episode: 230, duration: 2.033s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.055 [0.000, 2.000], mean observation: -0.261 [-0.822, 0.023], loss: 7.850084, mean_squared_error: 2488.887207, mean_q: -60.724194\n",
      " 46156/100000: episode: 231, duration: 2.022s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.985 [0.000, 2.000], mean observation: -0.268 [-0.716, 0.019], loss: 10.619437, mean_squared_error: 2476.693359, mean_q: -60.551201\n",
      " 46356/100000: episode: 232, duration: 2.005s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.040 [0.000, 2.000], mean observation: -0.255 [-0.999, 0.039], loss: 8.655937, mean_squared_error: 2425.180664, mean_q: -59.878990\n",
      " 46556/100000: episode: 233, duration: 1.978s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.785 [0.000, 2.000], mean observation: -0.293 [-0.999, 0.040], loss: 10.083517, mean_squared_error: 2408.104980, mean_q: -59.669388\n",
      " 46756/100000: episode: 234, duration: 2.007s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.835 [0.000, 2.000], mean observation: -0.271 [-0.840, 0.021], loss: 9.004616, mean_squared_error: 2391.324707, mean_q: -59.495861\n",
      " 46956/100000: episode: 235, duration: 2.026s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.905 [0.000, 2.000], mean observation: -0.258 [-0.780, 0.027], loss: 9.691462, mean_squared_error: 2360.583984, mean_q: -59.159950\n",
      " 47156/100000: episode: 236, duration: 2.018s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.855 [0.000, 2.000], mean observation: -0.281 [-1.062, 0.044], loss: 9.844813, mean_squared_error: 2311.847168, mean_q: -58.479298\n",
      " 47356/100000: episode: 237, duration: 2.045s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.260 [0.000, 2.000], mean observation: -0.244 [-0.765, 0.027], loss: 10.616779, mean_squared_error: 2256.213867, mean_q: -57.732109\n",
      " 47556/100000: episode: 238, duration: 2.031s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.930 [0.000, 2.000], mean observation: -0.285 [-1.102, 0.041], loss: 6.667766, mean_squared_error: 2254.532471, mean_q: -57.763203\n",
      " 47756/100000: episode: 239, duration: 2.026s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.965 [0.000, 2.000], mean observation: -0.265 [-0.790, 0.033], loss: 7.248804, mean_squared_error: 2275.715088, mean_q: -58.024899\n",
      " 47956/100000: episode: 240, duration: 2.007s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.065 [0.000, 2.000], mean observation: -0.260 [-0.859, 0.034], loss: 10.127762, mean_squared_error: 2244.667480, mean_q: -57.582706\n",
      " 48156/100000: episode: 241, duration: 2.022s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.020 [0.000, 2.000], mean observation: -0.243 [-1.076, 0.186], loss: 7.350751, mean_squared_error: 2279.871826, mean_q: -58.082397\n",
      " 48356/100000: episode: 242, duration: 2.014s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.910 [0.000, 2.000], mean observation: -0.273 [-0.896, 0.025], loss: 6.256491, mean_squared_error: 2351.283691, mean_q: -59.028088\n",
      " 48556/100000: episode: 243, duration: 2.045s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.040 [0.000, 2.000], mean observation: -0.254 [-0.911, 0.022], loss: 7.421457, mean_squared_error: 2395.746338, mean_q: -59.587112\n",
      " 48756/100000: episode: 244, duration: 2.005s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.170 [0.000, 2.000], mean observation: -0.249 [-0.808, 0.027], loss: 10.990891, mean_squared_error: 2379.989990, mean_q: -59.330147\n",
      " 48956/100000: episode: 245, duration: 1.994s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.065 [0.000, 2.000], mean observation: -0.272 [-0.967, 0.036], loss: 8.602706, mean_squared_error: 2325.123291, mean_q: -58.620148\n",
      " 49156/100000: episode: 246, duration: 2.042s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.915 [0.000, 2.000], mean observation: -0.293 [-1.200, 0.054], loss: 8.879953, mean_squared_error: 2327.308838, mean_q: -58.640194\n",
      " 49356/100000: episode: 247, duration: 1.981s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.865 [0.000, 2.000], mean observation: -0.269 [-0.839, 0.024], loss: 9.982747, mean_squared_error: 2292.472900, mean_q: -58.259300\n",
      " 49556/100000: episode: 248, duration: 1.987s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.045 [0.000, 2.000], mean observation: -0.235 [-1.003, 0.266], loss: 10.607958, mean_squared_error: 2304.187012, mean_q: -58.301060\n",
      " 49756/100000: episode: 249, duration: 2.041s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.795 [0.000, 2.000], mean observation: -0.287 [-1.113, 0.044], loss: 8.830270, mean_squared_error: 2257.149902, mean_q: -57.763588\n",
      " 49915/100000: episode: 250, duration: 1.614s, episode steps: 159, steps per second: 99, episode reward: -159.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.101 [0.000, 2.000], mean observation: -0.197 [-1.005, 0.500], loss: 12.113419, mean_squared_error: 2216.596191, mean_q: -57.108822\n",
      " 50115/100000: episode: 251, duration: 2.043s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.205 [0.000, 2.000], mean observation: -0.245 [-0.925, 0.022], loss: 9.351426, mean_squared_error: 2137.940674, mean_q: -56.125946\n",
      " 50315/100000: episode: 252, duration: 2.036s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.925 [0.000, 2.000], mean observation: -0.265 [-0.803, 0.030], loss: 7.797863, mean_squared_error: 2141.834473, mean_q: -56.309738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50515/100000: episode: 253, duration: 2.005s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.940 [0.000, 2.000], mean observation: -0.261 [-0.772, 0.020], loss: 8.017023, mean_squared_error: 2188.468994, mean_q: -56.968063\n",
      " 50715/100000: episode: 254, duration: 2.000s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.820 [0.000, 2.000], mean observation: -0.287 [-0.923, 0.028], loss: 7.223371, mean_squared_error: 2241.645996, mean_q: -57.604279\n",
      " 50915/100000: episode: 255, duration: 2.003s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.200 [0.000, 2.000], mean observation: -0.252 [-0.758, 0.028], loss: 8.627160, mean_squared_error: 2266.666504, mean_q: -57.972977\n",
      " 51115/100000: episode: 256, duration: 2.045s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.800 [0.000, 2.000], mean observation: -0.296 [-1.040, 0.032], loss: 9.464138, mean_squared_error: 2293.885254, mean_q: -58.236748\n",
      " 51315/100000: episode: 257, duration: 2.032s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.055 [0.000, 2.000], mean observation: -0.257 [-0.722, 0.020], loss: 8.461804, mean_squared_error: 2228.973145, mean_q: -57.428818\n",
      " 51515/100000: episode: 258, duration: 2.026s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.920 [0.000, 2.000], mean observation: -0.289 [-1.009, 0.046], loss: 8.385960, mean_squared_error: 2274.559570, mean_q: -58.027679\n",
      " 51715/100000: episode: 259, duration: 2.002s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.015 [0.000, 2.000], mean observation: -0.271 [-0.995, 0.030], loss: 9.883668, mean_squared_error: 2279.304199, mean_q: -58.028809\n",
      " 51915/100000: episode: 260, duration: 2.001s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.000 [0.000, 2.000], mean observation: -0.269 [-0.814, 0.034], loss: 7.917827, mean_squared_error: 2286.633545, mean_q: -58.183144\n",
      " 52115/100000: episode: 261, duration: 2.000s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.230 [0.000, 2.000], mean observation: -0.253 [-0.696, 0.024], loss: 9.248948, mean_squared_error: 2306.663818, mean_q: -58.337929\n",
      " 52315/100000: episode: 262, duration: 2.024s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.205 [0.000, 2.000], mean observation: -0.245 [-0.851, 0.019], loss: 8.127356, mean_squared_error: 2255.663818, mean_q: -57.723759\n",
      " 52515/100000: episode: 263, duration: 2.033s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.975 [0.000, 2.000], mean observation: -0.221 [-1.200, 0.367], loss: 10.240017, mean_squared_error: 2232.346680, mean_q: -57.380898\n",
      " 52715/100000: episode: 264, duration: 2.114s, episode steps: 200, steps per second: 95, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.130 [0.000, 2.000], mean observation: -0.261 [-1.012, 0.016], loss: 7.866301, mean_squared_error: 2240.327148, mean_q: -57.584995\n",
      " 52915/100000: episode: 265, duration: 2.024s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.070 [0.000, 2.000], mean observation: -0.267 [-1.004, 0.040], loss: 9.214832, mean_squared_error: 2237.538086, mean_q: -57.529526\n",
      " 53115/100000: episode: 266, duration: 2.031s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.880 [0.000, 2.000], mean observation: -0.237 [-0.822, 0.179], loss: 8.363740, mean_squared_error: 2223.447754, mean_q: -57.302784\n",
      " 53315/100000: episode: 267, duration: 2.027s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.025 [0.000, 2.000], mean observation: -0.274 [-0.937, 0.042], loss: 7.690170, mean_squared_error: 2235.438965, mean_q: -57.459225\n",
      " 53515/100000: episode: 268, duration: 2.042s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.420 [0.000, 2.000], mean observation: -0.251 [-1.144, 0.042], loss: 9.908099, mean_squared_error: 2156.492920, mean_q: -56.398701\n",
      " 53715/100000: episode: 269, duration: 2.029s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.785 [0.000, 2.000], mean observation: -0.282 [-0.859, 0.028], loss: 7.410793, mean_squared_error: 2166.252441, mean_q: -56.532150\n",
      " 53915/100000: episode: 270, duration: 2.008s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.870 [0.000, 2.000], mean observation: -0.306 [-1.169, 0.059], loss: 6.350021, mean_squared_error: 2249.682129, mean_q: -57.731396\n",
      " 54115/100000: episode: 271, duration: 2.036s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.970 [0.000, 2.000], mean observation: -0.263 [-0.806, 0.022], loss: 8.720409, mean_squared_error: 2273.407471, mean_q: -57.960812\n",
      " 54315/100000: episode: 272, duration: 2.011s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.750 [0.000, 2.000], mean observation: -0.279 [-1.053, 0.046], loss: 8.090943, mean_squared_error: 2279.890869, mean_q: -58.143711\n",
      " 54515/100000: episode: 273, duration: 2.032s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.035 [0.000, 2.000], mean observation: -0.260 [-0.864, 0.028], loss: 7.998806, mean_squared_error: 2319.705811, mean_q: -58.617100\n",
      " 54715/100000: episode: 274, duration: 2.016s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.710 [0.000, 2.000], mean observation: -0.287 [-0.744, 0.022], loss: 9.087466, mean_squared_error: 2310.748779, mean_q: -58.408325\n",
      " 54915/100000: episode: 275, duration: 1.985s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.020 [0.000, 2.000], mean observation: -0.280 [-1.058, 0.042], loss: 8.055150, mean_squared_error: 2313.304932, mean_q: -58.564404\n",
      " 55115/100000: episode: 276, duration: 2.068s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.165 [0.000, 2.000], mean observation: -0.242 [-0.705, 0.021], loss: 9.029169, mean_squared_error: 2299.988281, mean_q: -58.240746\n",
      " 55315/100000: episode: 277, duration: 2.025s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.930 [0.000, 2.000], mean observation: -0.269 [-0.965, 0.043], loss: 9.206953, mean_squared_error: 2197.961182, mean_q: -56.864277\n",
      " 55515/100000: episode: 278, duration: 1.994s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.845 [0.000, 2.000], mean observation: -0.275 [-0.850, 0.016], loss: 11.542885, mean_squared_error: 2166.119141, mean_q: -56.604481\n",
      " 55715/100000: episode: 279, duration: 2.028s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.815 [0.000, 2.000], mean observation: -0.267 [-0.869, 0.033], loss: 6.271578, mean_squared_error: 2192.981201, mean_q: -57.053326\n",
      " 55915/100000: episode: 280, duration: 2.010s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.125 [0.000, 2.000], mean observation: -0.247 [-0.880, 0.029], loss: 7.843647, mean_squared_error: 2225.095215, mean_q: -57.355453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56115/100000: episode: 281, duration: 2.050s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.295 [0.000, 2.000], mean observation: -0.253 [-0.919, 0.031], loss: 7.453273, mean_squared_error: 2251.529053, mean_q: -57.763161\n",
      " 56315/100000: episode: 282, duration: 2.035s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.005 [0.000, 2.000], mean observation: -0.283 [-1.095, 0.044], loss: 7.049463, mean_squared_error: 2282.312256, mean_q: -58.148746\n",
      " 56515/100000: episode: 283, duration: 2.016s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.720 [0.000, 2.000], mean observation: -0.284 [-1.200, 0.211], loss: 8.321385, mean_squared_error: 2274.273682, mean_q: -57.939743\n",
      " 56715/100000: episode: 284, duration: 2.112s, episode steps: 200, steps per second: 95, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.170 [0.000, 2.000], mean observation: -0.238 [-0.800, 0.032], loss: 8.322787, mean_squared_error: 2271.385254, mean_q: -57.946514\n",
      " 56915/100000: episode: 285, duration: 2.256s, episode steps: 200, steps per second: 89, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.845 [0.000, 2.000], mean observation: -0.268 [-0.952, 0.034], loss: 7.036253, mean_squared_error: 2284.192383, mean_q: -58.089863\n",
      " 57115/100000: episode: 286, duration: 2.062s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.930 [0.000, 2.000], mean observation: -0.270 [-0.815, 0.013], loss: 9.233509, mean_squared_error: 2213.953125, mean_q: -57.153790\n",
      " 57315/100000: episode: 287, duration: 2.021s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.180 [0.000, 2.000], mean observation: -0.254 [-0.870, 0.030], loss: 8.564242, mean_squared_error: 2223.993652, mean_q: -57.418869\n",
      " 57515/100000: episode: 288, duration: 2.033s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.095 [0.000, 2.000], mean observation: -0.246 [-0.924, 0.033], loss: 9.808647, mean_squared_error: 2204.692871, mean_q: -57.125492\n",
      " 57715/100000: episode: 289, duration: 2.026s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.125 [0.000, 2.000], mean observation: -0.254 [-0.856, 0.032], loss: 7.963583, mean_squared_error: 2200.873047, mean_q: -57.038837\n",
      " 57915/100000: episode: 290, duration: 2.011s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.135 [0.000, 2.000], mean observation: -0.263 [-1.064, 0.038], loss: 9.998240, mean_squared_error: 2195.982422, mean_q: -56.955936\n",
      " 58115/100000: episode: 291, duration: 2.011s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.930 [0.000, 2.000], mean observation: -0.262 [-0.718, 0.019], loss: 8.749962, mean_squared_error: 2163.106445, mean_q: -56.561989\n",
      " 58315/100000: episode: 292, duration: 2.046s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.780 [0.000, 2.000], mean observation: -0.302 [-1.078, 0.051], loss: 10.741494, mean_squared_error: 2143.066895, mean_q: -56.303967\n",
      " 58515/100000: episode: 293, duration: 1.987s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.990 [0.000, 2.000], mean observation: -0.252 [-0.864, 0.022], loss: 8.196629, mean_squared_error: 2097.863770, mean_q: -55.634434\n",
      " 58715/100000: episode: 294, duration: 1.988s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.845 [0.000, 2.000], mean observation: -0.259 [-0.946, 0.041], loss: 8.658833, mean_squared_error: 2069.553223, mean_q: -55.276600\n",
      " 58915/100000: episode: 295, duration: 2.004s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.125 [0.000, 2.000], mean observation: -0.243 [-0.742, 0.021], loss: 7.030719, mean_squared_error: 2133.462891, mean_q: -56.248363\n",
      " 59115/100000: episode: 296, duration: 2.019s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.995 [0.000, 2.000], mean observation: -0.263 [-0.786, 0.024], loss: 7.588555, mean_squared_error: 2191.764404, mean_q: -56.971603\n",
      " 59315/100000: episode: 297, duration: 2.029s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.050 [0.000, 2.000], mean observation: -0.246 [-1.038, 0.033], loss: 7.617960, mean_squared_error: 2212.232422, mean_q: -57.251129\n",
      " 59515/100000: episode: 298, duration: 2.032s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.030 [0.000, 2.000], mean observation: -0.255 [-1.200, 0.059], loss: 9.895282, mean_squared_error: 2178.861816, mean_q: -56.609806\n",
      " 59715/100000: episode: 299, duration: 2.015s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.870 [0.000, 2.000], mean observation: -0.253 [-1.200, 0.051], loss: 6.974626, mean_squared_error: 2211.270996, mean_q: -57.214867\n",
      " 59915/100000: episode: 300, duration: 2.002s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.995 [0.000, 2.000], mean observation: -0.265 [-0.684, 0.010], loss: 5.758402, mean_squared_error: 2233.271484, mean_q: -57.477989\n",
      " 60115/100000: episode: 301, duration: 2.007s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.930 [0.000, 2.000], mean observation: -0.264 [-0.795, 0.028], loss: 7.758844, mean_squared_error: 2274.954590, mean_q: -58.008251\n",
      " 60315/100000: episode: 302, duration: 2.047s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.805 [0.000, 2.000], mean observation: -0.275 [-0.892, 0.031], loss: 5.433773, mean_squared_error: 2295.436523, mean_q: -58.322220\n",
      " 60515/100000: episode: 303, duration: 2.009s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.960 [0.000, 2.000], mean observation: -0.255 [-0.777, 0.027], loss: 6.641360, mean_squared_error: 2390.831055, mean_q: -59.496391\n",
      " 60715/100000: episode: 304, duration: 2.004s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.030 [0.000, 2.000], mean observation: -0.261 [-0.964, 0.028], loss: 9.246915, mean_squared_error: 2409.249268, mean_q: -59.678967\n",
      " 60915/100000: episode: 305, duration: 2.022s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.975 [0.000, 2.000], mean observation: -0.268 [-0.776, 0.022], loss: 11.790642, mean_squared_error: 2371.772217, mean_q: -59.117397\n",
      " 61115/100000: episode: 306, duration: 2.017s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.950 [0.000, 2.000], mean observation: -0.285 [-1.012, 0.045], loss: 7.241531, mean_squared_error: 2342.072266, mean_q: -58.869225\n",
      " 61315/100000: episode: 307, duration: 2.015s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.820 [0.000, 2.000], mean observation: -0.283 [-0.765, 0.024], loss: 8.984315, mean_squared_error: 2356.099121, mean_q: -58.984688\n",
      " 61515/100000: episode: 308, duration: 2.020s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.815 [0.000, 2.000], mean observation: -0.281 [-0.899, 0.030], loss: 8.966026, mean_squared_error: 2344.835205, mean_q: -58.929733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61715/100000: episode: 309, duration: 2.042s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.045 [0.000, 2.000], mean observation: -0.255 [-1.005, 0.046], loss: 7.886537, mean_squared_error: 2349.187744, mean_q: -58.959473\n",
      " 61915/100000: episode: 310, duration: 1.988s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.150 [0.000, 2.000], mean observation: -0.248 [-0.825, 0.030], loss: 8.070141, mean_squared_error: 2344.855713, mean_q: -58.879131\n",
      " 62115/100000: episode: 311, duration: 2.027s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.745 [0.000, 2.000], mean observation: -0.295 [-0.955, 0.031], loss: 12.448368, mean_squared_error: 2252.385254, mean_q: -57.571621\n",
      " 62315/100000: episode: 312, duration: 2.031s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.730 [0.000, 2.000], mean observation: -0.284 [-0.803, 0.017], loss: 9.829459, mean_squared_error: 2189.166748, mean_q: -56.923038\n",
      " 62515/100000: episode: 313, duration: 2.025s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.820 [0.000, 2.000], mean observation: -0.291 [-1.200, 0.044], loss: 6.352937, mean_squared_error: 2214.997070, mean_q: -57.289627\n",
      " 62715/100000: episode: 314, duration: 2.027s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.800 [0.000, 2.000], mean observation: -0.282 [-0.738, 0.026], loss: 7.220862, mean_squared_error: 2250.806885, mean_q: -57.730927\n",
      " 62915/100000: episode: 315, duration: 2.023s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.130 [0.000, 2.000], mean observation: -0.255 [-0.696, 0.020], loss: 9.152127, mean_squared_error: 2279.688721, mean_q: -58.112648\n",
      " 63115/100000: episode: 316, duration: 2.022s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.810 [0.000, 2.000], mean observation: -0.278 [-1.031, 0.038], loss: 7.627034, mean_squared_error: 2309.867188, mean_q: -58.536133\n",
      " 63315/100000: episode: 317, duration: 2.000s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.090 [0.000, 2.000], mean observation: -0.259 [-0.881, 0.032], loss: 10.050321, mean_squared_error: 2304.672607, mean_q: -58.261051\n",
      " 63515/100000: episode: 318, duration: 1.998s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.680 [0.000, 2.000], mean observation: -0.298 [-0.929, 0.033], loss: 8.619678, mean_squared_error: 2277.571289, mean_q: -58.044731\n",
      " 63715/100000: episode: 319, duration: 2.024s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.120 [0.000, 2.000], mean observation: -0.262 [-0.814, 0.025], loss: 6.194620, mean_squared_error: 2301.336670, mean_q: -58.458340\n",
      " 63915/100000: episode: 320, duration: 2.013s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.825 [0.000, 2.000], mean observation: -0.264 [-0.694, 0.016], loss: 9.045413, mean_squared_error: 2336.501465, mean_q: -58.791115\n",
      " 64115/100000: episode: 321, duration: 2.024s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.185 [0.000, 2.000], mean observation: -0.242 [-0.761, 0.020], loss: 10.573668, mean_squared_error: 2311.288818, mean_q: -58.460419\n",
      " 64315/100000: episode: 322, duration: 2.019s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.970 [0.000, 2.000], mean observation: -0.258 [-0.830, 0.025], loss: 7.162436, mean_squared_error: 2295.343506, mean_q: -58.325741\n",
      " 64515/100000: episode: 323, duration: 2.073s, episode steps: 200, steps per second: 96, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.160 [0.000, 2.000], mean observation: -0.253 [-0.802, 0.027], loss: 9.809724, mean_squared_error: 2308.928955, mean_q: -58.405933\n",
      " 64715/100000: episode: 324, duration: 2.044s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.990 [0.000, 2.000], mean observation: -0.290 [-1.113, 0.051], loss: 8.291744, mean_squared_error: 2312.761963, mean_q: -58.511398\n",
      " 64915/100000: episode: 325, duration: 2.004s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.905 [0.000, 2.000], mean observation: -0.254 [-0.679, 0.025], loss: 7.613565, mean_squared_error: 2354.151611, mean_q: -59.096691\n",
      " 65115/100000: episode: 326, duration: 2.016s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.085 [0.000, 2.000], mean observation: -0.242 [-0.859, 0.037], loss: 8.833540, mean_squared_error: 2354.393066, mean_q: -59.072475\n",
      " 65315/100000: episode: 327, duration: 2.037s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.020 [0.000, 2.000], mean observation: -0.264 [-1.004, 0.125], loss: 6.128762, mean_squared_error: 2399.297852, mean_q: -59.646206\n",
      " 65515/100000: episode: 328, duration: 2.030s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.075 [0.000, 2.000], mean observation: -0.264 [-0.839, 0.024], loss: 7.882058, mean_squared_error: 2462.672852, mean_q: -60.395931\n",
      " 65715/100000: episode: 329, duration: 2.033s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.110 [0.000, 2.000], mean observation: -0.267 [-0.975, 0.048], loss: 9.001930, mean_squared_error: 2473.621582, mean_q: -60.491989\n",
      " 65915/100000: episode: 330, duration: 2.005s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.945 [0.000, 2.000], mean observation: -0.260 [-0.883, 0.027], loss: 10.405383, mean_squared_error: 2428.393799, mean_q: -59.968945\n",
      " 66115/100000: episode: 331, duration: 2.007s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.110 [0.000, 2.000], mean observation: -0.252 [-0.964, 0.031], loss: 7.140019, mean_squared_error: 2410.741455, mean_q: -59.779564\n",
      " 66315/100000: episode: 332, duration: 2.008s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.850 [0.000, 2.000], mean observation: -0.265 [-0.694, 0.026], loss: 8.957455, mean_squared_error: 2432.359375, mean_q: -60.000332\n",
      " 66515/100000: episode: 333, duration: 1.998s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.855 [0.000, 2.000], mean observation: -0.282 [-0.820, 0.031], loss: 8.114986, mean_squared_error: 2443.002930, mean_q: -60.136299\n",
      " 66715/100000: episode: 334, duration: 1.989s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.090 [0.000, 2.000], mean observation: -0.228 [-1.017, 0.087], loss: 9.401974, mean_squared_error: 2447.278809, mean_q: -60.129650\n",
      " 66915/100000: episode: 335, duration: 1.976s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.080 [0.000, 2.000], mean observation: -0.262 [-0.813, 0.031], loss: 7.693584, mean_squared_error: 2435.121094, mean_q: -60.071701\n",
      " 67115/100000: episode: 336, duration: 2.071s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.825 [0.000, 2.000], mean observation: -0.299 [-1.200, 0.035], loss: 6.513728, mean_squared_error: 2497.556641, mean_q: -60.815762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67315/100000: episode: 337, duration: 2.016s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.910 [0.000, 2.000], mean observation: -0.235 [-1.200, 0.090], loss: 8.816702, mean_squared_error: 2518.903809, mean_q: -60.991318\n",
      " 67515/100000: episode: 338, duration: 2.004s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.895 [0.000, 2.000], mean observation: -0.278 [-1.058, 0.041], loss: 8.202690, mean_squared_error: 2499.711182, mean_q: -60.792500\n",
      " 67715/100000: episode: 339, duration: 2.002s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.710 [0.000, 2.000], mean observation: -0.276 [-0.735, 0.019], loss: 8.878331, mean_squared_error: 2461.158691, mean_q: -60.335995\n",
      " 67915/100000: episode: 340, duration: 2.042s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.625 [0.000, 2.000], mean observation: -0.280 [-0.779, 0.015], loss: 7.338408, mean_squared_error: 2449.608643, mean_q: -60.264004\n",
      " 68115/100000: episode: 341, duration: 2.025s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.185 [0.000, 2.000], mean observation: -0.249 [-0.706, 0.017], loss: 9.496535, mean_squared_error: 2457.959961, mean_q: -60.291714\n",
      " 68315/100000: episode: 342, duration: 2.012s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.080 [0.000, 2.000], mean observation: -0.216 [-1.029, 0.323], loss: 9.343388, mean_squared_error: 2415.211670, mean_q: -59.738926\n",
      " 68515/100000: episode: 343, duration: 1.998s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.860 [0.000, 2.000], mean observation: -0.252 [-0.783, 0.032], loss: 8.493644, mean_squared_error: 2409.369629, mean_q: -59.737560\n",
      " 68715/100000: episode: 344, duration: 2.276s, episode steps: 200, steps per second: 88, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.885 [0.000, 2.000], mean observation: -0.270 [-0.879, 0.034], loss: 11.082024, mean_squared_error: 2386.503174, mean_q: -59.390701\n",
      " 68915/100000: episode: 345, duration: 2.247s, episode steps: 200, steps per second: 89, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.070 [0.000, 2.000], mean observation: -0.256 [-0.746, 0.028], loss: 7.428076, mean_squared_error: 2385.507568, mean_q: -59.474743\n",
      " 69110/100000: episode: 346, duration: 2.161s, episode steps: 195, steps per second: 90, episode reward: -195.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.062 [0.000, 2.000], mean observation: -0.228 [-1.200, 0.523], loss: 7.633029, mean_squared_error: 2450.459473, mean_q: -60.193966\n",
      " 69310/100000: episode: 347, duration: 2.265s, episode steps: 200, steps per second: 88, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.955 [0.000, 2.000], mean observation: -0.259 [-0.806, 0.024], loss: 13.132036, mean_squared_error: 2373.705566, mean_q: -59.146587\n",
      " 69510/100000: episode: 348, duration: 2.191s, episode steps: 200, steps per second: 91, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.305 [0.000, 2.000], mean observation: -0.244 [-0.756, 0.020], loss: 7.905303, mean_squared_error: 2325.705322, mean_q: -58.692013\n",
      " 69710/100000: episode: 349, duration: 2.339s, episode steps: 200, steps per second: 86, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.975 [0.000, 2.000], mean observation: -0.245 [-0.786, 0.031], loss: 6.176233, mean_squared_error: 2344.861084, mean_q: -58.993374\n",
      " 69910/100000: episode: 350, duration: 2.449s, episode steps: 200, steps per second: 82, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.800 [0.000, 2.000], mean observation: -0.280 [-0.820, 0.029], loss: 11.103850, mean_squared_error: 2340.214600, mean_q: -58.800350\n",
      " 70110/100000: episode: 351, duration: 2.657s, episode steps: 200, steps per second: 75, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.140 [0.000, 2.000], mean observation: -0.254 [-0.699, 0.024], loss: 8.516911, mean_squared_error: 2321.218018, mean_q: -58.687187\n",
      " 70310/100000: episode: 352, duration: 2.111s, episode steps: 200, steps per second: 95, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.000 [0.000, 2.000], mean observation: -0.270 [-0.943, 0.036], loss: 7.340414, mean_squared_error: 2350.456055, mean_q: -58.968605\n",
      " 70510/100000: episode: 353, duration: 2.156s, episode steps: 200, steps per second: 93, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.720 [0.000, 2.000], mean observation: -0.296 [-0.949, 0.034], loss: 11.009346, mean_squared_error: 2331.131836, mean_q: -58.685867\n",
      " 70710/100000: episode: 354, duration: 2.054s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.900 [0.000, 2.000], mean observation: -0.261 [-0.926, 0.031], loss: 9.562418, mean_squared_error: 2291.520264, mean_q: -58.224884\n",
      " 70910/100000: episode: 355, duration: 2.047s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.045 [0.000, 2.000], mean observation: -0.257 [-0.750, 0.024], loss: 9.525415, mean_squared_error: 2282.449707, mean_q: -58.174053\n",
      " 71110/100000: episode: 356, duration: 2.074s, episode steps: 200, steps per second: 96, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.860 [0.000, 2.000], mean observation: -0.283 [-1.046, 0.030], loss: 10.610269, mean_squared_error: 2255.848633, mean_q: -57.704926\n",
      " 71310/100000: episode: 357, duration: 2.430s, episode steps: 200, steps per second: 82, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.075 [0.000, 2.000], mean observation: -0.252 [-1.076, 0.046], loss: 8.669400, mean_squared_error: 2258.658203, mean_q: -57.781761\n",
      " 71510/100000: episode: 358, duration: 2.060s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.090 [0.000, 2.000], mean observation: -0.262 [-0.855, 0.025], loss: 8.813133, mean_squared_error: 2254.817139, mean_q: -57.768726\n",
      " 71710/100000: episode: 359, duration: 2.083s, episode steps: 200, steps per second: 96, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.100 [0.000, 2.000], mean observation: -0.258 [-1.200, 0.172], loss: 9.541884, mean_squared_error: 2234.487793, mean_q: -57.548805\n",
      " 71910/100000: episode: 360, duration: 2.039s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.080 [0.000, 2.000], mean observation: -0.248 [-0.806, 0.025], loss: 7.459542, mean_squared_error: 2275.738525, mean_q: -58.061073\n",
      " 72110/100000: episode: 361, duration: 2.035s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.080 [0.000, 2.000], mean observation: -0.253 [-0.924, 0.036], loss: 10.695403, mean_squared_error: 2238.416016, mean_q: -57.585102\n",
      " 72310/100000: episode: 362, duration: 2.023s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.180 [0.000, 2.000], mean observation: -0.253 [-0.780, 0.025], loss: 6.066062, mean_squared_error: 2272.274658, mean_q: -58.045826\n",
      " 72510/100000: episode: 363, duration: 2.031s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.695 [0.000, 2.000], mean observation: -0.305 [-1.101, 0.040], loss: 7.634247, mean_squared_error: 2339.437256, mean_q: -58.920059\n",
      " 72710/100000: episode: 364, duration: 2.024s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.925 [0.000, 2.000], mean observation: -0.278 [-0.900, 0.037], loss: 9.559861, mean_squared_error: 2311.862305, mean_q: -58.489735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72910/100000: episode: 365, duration: 2.092s, episode steps: 200, steps per second: 96, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.105 [0.000, 2.000], mean observation: -0.256 [-0.856, 0.026], loss: 6.571412, mean_squared_error: 2351.359619, mean_q: -59.041630\n",
      " 73110/100000: episode: 366, duration: 2.066s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.775 [0.000, 2.000], mean observation: -0.280 [-0.759, 0.020], loss: 6.937117, mean_squared_error: 2402.897461, mean_q: -59.643673\n",
      " 73310/100000: episode: 367, duration: 2.043s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.085 [0.000, 2.000], mean observation: -0.251 [-0.686, 0.018], loss: 9.740968, mean_squared_error: 2413.763428, mean_q: -59.815697\n",
      " 73510/100000: episode: 368, duration: 2.150s, episode steps: 200, steps per second: 93, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.005 [0.000, 2.000], mean observation: -0.258 [-0.703, 0.022], loss: 7.837725, mean_squared_error: 2414.822754, mean_q: -59.802322\n",
      " 73710/100000: episode: 369, duration: 2.401s, episode steps: 200, steps per second: 83, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.865 [0.000, 2.000], mean observation: -0.262 [-1.129, 0.048], loss: 8.961287, mean_squared_error: 2420.052490, mean_q: -59.718555\n",
      " 73910/100000: episode: 370, duration: 2.119s, episode steps: 200, steps per second: 94, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.865 [0.000, 2.000], mean observation: -0.273 [-0.970, 0.038], loss: 9.637815, mean_squared_error: 2388.389893, mean_q: -59.465683\n",
      " 74110/100000: episode: 371, duration: 2.517s, episode steps: 200, steps per second: 79, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.065 [0.000, 2.000], mean observation: -0.248 [-0.822, 0.026], loss: 7.698884, mean_squared_error: 2414.466797, mean_q: -59.824131\n",
      " 74310/100000: episode: 372, duration: 2.801s, episode steps: 200, steps per second: 71, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.950 [0.000, 2.000], mean observation: -0.254 [-0.965, 0.046], loss: 11.687168, mean_squared_error: 2356.598389, mean_q: -58.916172\n",
      " 74510/100000: episode: 373, duration: 2.824s, episode steps: 200, steps per second: 71, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.985 [0.000, 2.000], mean observation: -0.252 [-0.762, 0.020], loss: 7.553617, mean_squared_error: 2344.141602, mean_q: -58.963081\n",
      " 74710/100000: episode: 374, duration: 2.197s, episode steps: 200, steps per second: 91, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.085 [0.000, 2.000], mean observation: -0.245 [-1.200, 0.049], loss: 9.705890, mean_squared_error: 2306.024414, mean_q: -58.406319\n",
      " 74910/100000: episode: 375, duration: 2.060s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.195 [0.000, 2.000], mean observation: -0.256 [-0.744, 0.026], loss: 7.662427, mean_squared_error: 2298.410645, mean_q: -58.354969\n",
      " 75110/100000: episode: 376, duration: 2.308s, episode steps: 200, steps per second: 87, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.050 [0.000, 2.000], mean observation: -0.268 [-1.019, 0.044], loss: 5.409561, mean_squared_error: 2371.590332, mean_q: -59.375488\n",
      " 75310/100000: episode: 377, duration: 2.050s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.055 [0.000, 2.000], mean observation: -0.274 [-1.081, 0.051], loss: 7.915116, mean_squared_error: 2438.207520, mean_q: -60.134140\n",
      " 75510/100000: episode: 378, duration: 2.032s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.730 [0.000, 2.000], mean observation: -0.287 [-0.770, 0.028], loss: 8.502349, mean_squared_error: 2457.870605, mean_q: -60.184834\n",
      " 75710/100000: episode: 379, duration: 2.104s, episode steps: 200, steps per second: 95, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.705 [0.000, 2.000], mean observation: -0.279 [-0.774, 0.022], loss: 10.588336, mean_squared_error: 2351.014648, mean_q: -58.961193\n",
      " 75891/100000: episode: 380, duration: 1.863s, episode steps: 181, steps per second: 97, episode reward: -181.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.972 [0.000, 2.000], mean observation: -0.209 [-1.200, 0.524], loss: 7.760087, mean_squared_error: 2325.092773, mean_q: -58.580627\n",
      " 76091/100000: episode: 381, duration: 2.008s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.860 [0.000, 2.000], mean observation: -0.276 [-0.920, 0.043], loss: 7.920512, mean_squared_error: 2355.068848, mean_q: -59.054092\n",
      " 76291/100000: episode: 382, duration: 2.043s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.625 [0.000, 2.000], mean observation: -0.313 [-1.200, 0.045], loss: 11.111218, mean_squared_error: 2355.246826, mean_q: -59.030968\n",
      " 76486/100000: episode: 383, duration: 1.988s, episode steps: 195, steps per second: 98, episode reward: -195.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.282 [0.000, 2.000], mean observation: -0.253 [-1.197, 0.544], loss: 7.839745, mean_squared_error: 2294.184570, mean_q: -58.261799\n",
      " 76686/100000: episode: 384, duration: 2.005s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.700 [0.000, 2.000], mean observation: -0.294 [-1.032, 0.037], loss: 9.706662, mean_squared_error: 2264.521973, mean_q: -57.864414\n",
      " 76886/100000: episode: 385, duration: 2.070s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.310 [0.000, 2.000], mean observation: -0.236 [-0.777, 0.017], loss: 7.573366, mean_squared_error: 2217.301514, mean_q: -57.284092\n",
      " 77086/100000: episode: 386, duration: 2.012s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.855 [0.000, 2.000], mean observation: -0.274 [-0.930, 0.036], loss: 8.896573, mean_squared_error: 2202.510498, mean_q: -57.099663\n",
      " 77286/100000: episode: 387, duration: 2.010s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.840 [0.000, 2.000], mean observation: -0.255 [-0.793, 0.032], loss: 12.067951, mean_squared_error: 2183.426270, mean_q: -56.779785\n",
      " 77486/100000: episode: 388, duration: 2.023s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.805 [0.000, 2.000], mean observation: -0.264 [-0.828, 0.036], loss: 8.817986, mean_squared_error: 2140.557129, mean_q: -56.285019\n",
      " 77686/100000: episode: 389, duration: 2.005s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.690 [0.000, 2.000], mean observation: -0.280 [-0.816, 0.022], loss: 8.684443, mean_squared_error: 2171.167480, mean_q: -56.703613\n",
      " 77886/100000: episode: 390, duration: 2.030s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.165 [0.000, 2.000], mean observation: -0.235 [-0.858, 0.152], loss: 9.145010, mean_squared_error: 2165.617920, mean_q: -56.621475\n",
      " 78086/100000: episode: 391, duration: 2.014s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.060 [0.000, 2.000], mean observation: -0.249 [-0.970, 0.226], loss: 7.455753, mean_squared_error: 2163.606201, mean_q: -56.572891\n",
      " 78286/100000: episode: 392, duration: 2.039s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.005 [0.000, 2.000], mean observation: -0.252 [-0.817, 0.024], loss: 6.471558, mean_squared_error: 2180.677246, mean_q: -56.799183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78486/100000: episode: 393, duration: 2.023s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.275 [0.000, 2.000], mean observation: -0.240 [-0.774, 0.030], loss: 6.682491, mean_squared_error: 2227.978271, mean_q: -57.497196\n",
      " 78686/100000: episode: 394, duration: 2.033s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.300 [0.000, 2.000], mean observation: -0.231 [-0.892, 0.036], loss: 5.588730, mean_squared_error: 2329.064941, mean_q: -58.778927\n",
      " 78886/100000: episode: 395, duration: 2.049s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.080 [0.000, 2.000], mean observation: -0.262 [-0.773, 0.033], loss: 5.846871, mean_squared_error: 2369.368896, mean_q: -59.287479\n",
      " 79086/100000: episode: 396, duration: 2.042s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.395 [0.000, 2.000], mean observation: -0.233 [-0.699, 0.026], loss: 6.572235, mean_squared_error: 2410.850098, mean_q: -59.708839\n",
      " 79286/100000: episode: 397, duration: 2.055s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.955 [0.000, 2.000], mean observation: -0.270 [-0.697, 0.019], loss: 7.147191, mean_squared_error: 2412.426025, mean_q: -59.837090\n",
      " 79486/100000: episode: 398, duration: 2.043s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.115 [0.000, 2.000], mean observation: -0.271 [-1.092, 0.117], loss: 8.607694, mean_squared_error: 2415.084961, mean_q: -59.739513\n",
      " 79686/100000: episode: 399, duration: 2.068s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.085 [0.000, 2.000], mean observation: -0.250 [-1.030, 0.038], loss: 9.827531, mean_squared_error: 2420.157715, mean_q: -59.858841\n",
      " 79886/100000: episode: 400, duration: 2.028s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.060 [0.000, 2.000], mean observation: -0.261 [-0.743, 0.027], loss: 6.713045, mean_squared_error: 2416.858154, mean_q: -59.819576\n",
      " 80086/100000: episode: 401, duration: 2.020s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.020 [0.000, 2.000], mean observation: -0.256 [-1.000, 0.207], loss: 9.666295, mean_squared_error: 2434.846924, mean_q: -60.013081\n",
      " 80286/100000: episode: 402, duration: 2.014s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.885 [0.000, 2.000], mean observation: -0.285 [-0.914, 0.033], loss: 10.103247, mean_squared_error: 2400.339355, mean_q: -59.626015\n",
      " 80486/100000: episode: 403, duration: 2.026s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.340 [0.000, 2.000], mean observation: -0.240 [-0.849, 0.035], loss: 9.701730, mean_squared_error: 2333.937256, mean_q: -58.742558\n",
      " 80686/100000: episode: 404, duration: 2.057s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.840 [0.000, 2.000], mean observation: -0.271 [-0.874, 0.027], loss: 10.607761, mean_squared_error: 2303.791016, mean_q: -58.443222\n",
      " 80886/100000: episode: 405, duration: 2.029s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.025 [0.000, 2.000], mean observation: -0.278 [-1.031, 0.040], loss: 6.888321, mean_squared_error: 2294.458008, mean_q: -58.279316\n",
      " 81086/100000: episode: 406, duration: 2.010s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.110 [0.000, 2.000], mean observation: -0.254 [-0.839, 0.035], loss: 7.661087, mean_squared_error: 2360.325928, mean_q: -59.089897\n",
      " 81286/100000: episode: 407, duration: 2.046s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.745 [0.000, 2.000], mean observation: -0.273 [-0.770, 0.018], loss: 7.783220, mean_squared_error: 2418.378906, mean_q: -59.889996\n",
      " 81486/100000: episode: 408, duration: 2.022s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.010 [0.000, 2.000], mean observation: -0.263 [-1.082, 0.053], loss: 8.391322, mean_squared_error: 2351.520508, mean_q: -58.926876\n",
      " 81686/100000: episode: 409, duration: 2.039s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.085 [0.000, 2.000], mean observation: -0.245 [-0.867, 0.038], loss: 6.206465, mean_squared_error: 2434.971680, mean_q: -60.088985\n",
      " 81886/100000: episode: 410, duration: 2.016s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.180 [0.000, 2.000], mean observation: -0.250 [-1.200, 0.031], loss: 6.948151, mean_squared_error: 2488.813965, mean_q: -60.789394\n",
      " 82086/100000: episode: 411, duration: 2.023s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.965 [0.000, 2.000], mean observation: -0.275 [-0.846, 0.028], loss: 9.230304, mean_squared_error: 2508.104736, mean_q: -60.932205\n",
      " 82286/100000: episode: 412, duration: 2.068s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.655 [0.000, 2.000], mean observation: -0.285 [-1.070, 0.038], loss: 9.469546, mean_squared_error: 2496.993652, mean_q: -60.749123\n",
      " 82486/100000: episode: 413, duration: 2.025s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.045 [0.000, 2.000], mean observation: -0.268 [-0.832, 0.029], loss: 7.392885, mean_squared_error: 2500.594727, mean_q: -60.904366\n",
      " 82686/100000: episode: 414, duration: 2.045s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.785 [0.000, 2.000], mean observation: -0.286 [-0.912, 0.032], loss: 7.967161, mean_squared_error: 2511.406250, mean_q: -61.038719\n",
      " 82886/100000: episode: 415, duration: 2.033s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.135 [0.000, 2.000], mean observation: -0.232 [-0.798, 0.034], loss: 8.872876, mean_squared_error: 2509.384033, mean_q: -60.915577\n",
      " 83086/100000: episode: 416, duration: 2.078s, episode steps: 200, steps per second: 96, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.005 [0.000, 2.000], mean observation: -0.259 [-0.811, 0.026], loss: 10.669892, mean_squared_error: 2486.916748, mean_q: -60.647720\n",
      " 83286/100000: episode: 417, duration: 2.117s, episode steps: 200, steps per second: 94, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.115 [0.000, 2.000], mean observation: -0.246 [-0.795, 0.027], loss: 7.962310, mean_squared_error: 2445.421143, mean_q: -60.220829\n",
      " 83486/100000: episode: 418, duration: 2.250s, episode steps: 200, steps per second: 89, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.245 [0.000, 2.000], mean observation: -0.249 [-0.905, 0.039], loss: 10.635761, mean_squared_error: 2433.423828, mean_q: -60.048321\n",
      " 83686/100000: episode: 419, duration: 2.355s, episode steps: 200, steps per second: 85, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.025 [0.000, 2.000], mean observation: -0.266 [-0.795, 0.026], loss: 7.806757, mean_squared_error: 2471.364014, mean_q: -60.527821\n",
      " 83886/100000: episode: 420, duration: 2.177s, episode steps: 200, steps per second: 92, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.835 [0.000, 2.000], mean observation: -0.272 [-0.871, 0.027], loss: 9.201593, mean_squared_error: 2408.014160, mean_q: -59.668335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84086/100000: episode: 421, duration: 2.037s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.055 [0.000, 2.000], mean observation: -0.259 [-1.186, 0.026], loss: 9.059814, mean_squared_error: 2400.937500, mean_q: -59.579071\n",
      " 84286/100000: episode: 422, duration: 2.027s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.070 [0.000, 2.000], mean observation: -0.262 [-0.782, 0.014], loss: 7.954057, mean_squared_error: 2440.510986, mean_q: -60.178513\n",
      " 84486/100000: episode: 423, duration: 2.143s, episode steps: 200, steps per second: 93, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.635 [0.000, 2.000], mean observation: -0.286 [-0.816, 0.024], loss: 8.907812, mean_squared_error: 2443.375977, mean_q: -60.192192\n",
      " 84686/100000: episode: 424, duration: 2.098s, episode steps: 200, steps per second: 95, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.035 [0.000, 2.000], mean observation: -0.246 [-0.833, 0.034], loss: 8.924558, mean_squared_error: 2442.734131, mean_q: -60.087521\n",
      " 84886/100000: episode: 425, duration: 2.163s, episode steps: 200, steps per second: 92, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.645 [0.000, 2.000], mean observation: -0.289 [-0.799, 0.030], loss: 10.086386, mean_squared_error: 2412.674561, mean_q: -59.599140\n",
      " 85086/100000: episode: 426, duration: 2.035s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.030 [0.000, 2.000], mean observation: -0.264 [-0.992, 0.038], loss: 9.186427, mean_squared_error: 2335.235107, mean_q: -58.797531\n",
      " 85286/100000: episode: 427, duration: 2.033s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.860 [0.000, 2.000], mean observation: -0.291 [-1.161, 0.041], loss: 8.687051, mean_squared_error: 2327.482910, mean_q: -58.693981\n",
      " 85486/100000: episode: 428, duration: 2.061s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.800 [0.000, 2.000], mean observation: -0.274 [-0.813, 0.030], loss: 7.497872, mean_squared_error: 2314.389648, mean_q: -58.497002\n",
      " 85686/100000: episode: 429, duration: 2.023s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.925 [0.000, 2.000], mean observation: -0.258 [-0.791, 0.020], loss: 10.470115, mean_squared_error: 2326.628418, mean_q: -58.727329\n",
      " 85886/100000: episode: 430, duration: 1.991s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.745 [0.000, 2.000], mean observation: -0.277 [-0.731, 0.026], loss: 10.262826, mean_squared_error: 2294.666016, mean_q: -58.277744\n",
      " 86086/100000: episode: 431, duration: 2.041s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.745 [0.000, 2.000], mean observation: -0.270 [-1.011, 0.028], loss: 9.587244, mean_squared_error: 2256.502930, mean_q: -57.738945\n",
      " 86286/100000: episode: 432, duration: 2.006s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.180 [0.000, 2.000], mean observation: -0.243 [-0.755, 0.021], loss: 9.368832, mean_squared_error: 2258.705566, mean_q: -57.867748\n",
      " 86486/100000: episode: 433, duration: 2.014s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.385 [0.000, 2.000], mean observation: -0.218 [-0.696, 0.023], loss: 7.260480, mean_squared_error: 2249.956543, mean_q: -57.803055\n",
      " 86686/100000: episode: 434, duration: 2.029s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.935 [0.000, 2.000], mean observation: -0.260 [-0.931, 0.038], loss: 12.548010, mean_squared_error: 2197.524902, mean_q: -56.931366\n",
      " 86886/100000: episode: 435, duration: 2.049s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.960 [0.000, 2.000], mean observation: -0.267 [-0.675, 0.017], loss: 8.083294, mean_squared_error: 2195.297363, mean_q: -57.100861\n",
      " 87086/100000: episode: 436, duration: 2.311s, episode steps: 200, steps per second: 87, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.940 [0.000, 2.000], mean observation: -0.266 [-1.077, 0.047], loss: 5.719104, mean_squared_error: 2266.538330, mean_q: -57.991711\n",
      " 87286/100000: episode: 437, duration: 2.459s, episode steps: 200, steps per second: 81, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.915 [0.000, 2.000], mean observation: -0.287 [-1.174, 0.172], loss: 11.108912, mean_squared_error: 2279.899902, mean_q: -58.082451\n",
      " 87486/100000: episode: 438, duration: 2.103s, episode steps: 200, steps per second: 95, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.050 [0.000, 2.000], mean observation: -0.256 [-0.837, 0.036], loss: 7.326933, mean_squared_error: 2271.814697, mean_q: -58.054031\n",
      " 87686/100000: episode: 439, duration: 2.584s, episode steps: 200, steps per second: 77, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.310 [0.000, 2.000], mean observation: -0.244 [-0.867, 0.040], loss: 6.841143, mean_squared_error: 2313.360840, mean_q: -58.567345\n",
      " 87886/100000: episode: 440, duration: 2.631s, episode steps: 200, steps per second: 76, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.950 [0.000, 2.000], mean observation: -0.262 [-0.811, 0.024], loss: 8.855434, mean_squared_error: 2352.287842, mean_q: -59.099884\n",
      " 88086/100000: episode: 441, duration: 2.446s, episode steps: 200, steps per second: 82, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.075 [0.000, 2.000], mean observation: -0.251 [-0.898, 0.042], loss: 8.807011, mean_squared_error: 2380.992920, mean_q: -59.354355\n",
      " 88286/100000: episode: 442, duration: 2.357s, episode steps: 200, steps per second: 85, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.225 [0.000, 2.000], mean observation: -0.233 [-1.173, 0.049], loss: 9.844255, mean_squared_error: 2284.132324, mean_q: -58.095192\n",
      " 88486/100000: episode: 443, duration: 2.555s, episode steps: 200, steps per second: 78, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.100 [0.000, 2.000], mean observation: -0.247 [-0.808, 0.027], loss: 5.985536, mean_squared_error: 2345.230713, mean_q: -58.979549\n",
      " 88686/100000: episode: 444, duration: 2.585s, episode steps: 200, steps per second: 77, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.920 [0.000, 2.000], mean observation: -0.236 [-1.116, 0.314], loss: 9.495544, mean_squared_error: 2360.810547, mean_q: -59.116718\n",
      " 88886/100000: episode: 445, duration: 2.539s, episode steps: 200, steps per second: 79, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.145 [0.000, 2.000], mean observation: -0.258 [-0.766, 0.028], loss: 8.005953, mean_squared_error: 2348.234619, mean_q: -59.064854\n",
      " 89086/100000: episode: 446, duration: 2.560s, episode steps: 200, steps per second: 78, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.935 [0.000, 2.000], mean observation: -0.265 [-0.779, 0.019], loss: 8.321480, mean_squared_error: 2371.227783, mean_q: -59.274605\n",
      " 89286/100000: episode: 447, duration: 2.537s, episode steps: 200, steps per second: 79, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.220 [0.000, 2.000], mean observation: -0.239 [-1.121, 0.240], loss: 11.397749, mean_squared_error: 2304.972900, mean_q: -58.253387\n",
      " 89486/100000: episode: 448, duration: 2.524s, episode steps: 200, steps per second: 79, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.760 [0.000, 2.000], mean observation: -0.281 [-0.766, 0.022], loss: 7.913036, mean_squared_error: 2297.934814, mean_q: -58.259609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89686/100000: episode: 449, duration: 2.489s, episode steps: 200, steps per second: 80, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.220 [0.000, 2.000], mean observation: -0.245 [-0.687, 0.020], loss: 5.672208, mean_squared_error: 2353.608887, mean_q: -59.129669\n",
      " 89886/100000: episode: 450, duration: 2.493s, episode steps: 200, steps per second: 80, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.870 [0.000, 2.000], mean observation: -0.271 [-0.734, 0.021], loss: 10.388794, mean_squared_error: 2315.459961, mean_q: -58.472191\n",
      " 90086/100000: episode: 451, duration: 2.496s, episode steps: 200, steps per second: 80, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.735 [0.000, 2.000], mean observation: -0.303 [-1.135, 0.044], loss: 10.089344, mean_squared_error: 2279.269287, mean_q: -58.093826\n",
      " 90286/100000: episode: 452, duration: 2.193s, episode steps: 200, steps per second: 91, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.015 [0.000, 2.000], mean observation: -0.259 [-1.032, 0.049], loss: 9.276892, mean_squared_error: 2244.407227, mean_q: -57.601807\n",
      " 90486/100000: episode: 453, duration: 2.300s, episode steps: 200, steps per second: 87, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.020 [0.000, 2.000], mean observation: -0.279 [-1.021, 0.037], loss: 7.762222, mean_squared_error: 2279.749023, mean_q: -58.056969\n",
      " 90686/100000: episode: 454, duration: 2.228s, episode steps: 200, steps per second: 90, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.940 [0.000, 2.000], mean observation: -0.239 [-1.200, 0.412], loss: 10.788440, mean_squared_error: 2253.213379, mean_q: -57.666065\n",
      " 90886/100000: episode: 455, duration: 2.254s, episode steps: 200, steps per second: 89, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.235 [0.000, 2.000], mean observation: -0.240 [-0.839, 0.034], loss: 7.779636, mean_squared_error: 2269.781006, mean_q: -58.020714\n",
      " 91086/100000: episode: 456, duration: 2.238s, episode steps: 200, steps per second: 89, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.115 [0.000, 2.000], mean observation: -0.251 [-1.048, 0.044], loss: 10.167822, mean_squared_error: 2187.372803, mean_q: -56.847080\n",
      " 91286/100000: episode: 457, duration: 2.056s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.045 [0.000, 2.000], mean observation: -0.258 [-0.788, 0.032], loss: 5.761846, mean_squared_error: 2189.062744, mean_q: -56.986397\n",
      " 91486/100000: episode: 458, duration: 2.576s, episode steps: 200, steps per second: 78, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.185 [0.000, 2.000], mean observation: -0.258 [-0.889, 0.029], loss: 7.829164, mean_squared_error: 2262.036377, mean_q: -57.869572\n",
      " 91686/100000: episode: 459, duration: 2.320s, episode steps: 200, steps per second: 86, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.110 [0.000, 2.000], mean observation: -0.257 [-0.895, 0.034], loss: 10.358850, mean_squared_error: 2246.690430, mean_q: -57.676590\n",
      " 91886/100000: episode: 460, duration: 2.587s, episode steps: 200, steps per second: 77, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.660 [0.000, 2.000], mean observation: -0.286 [-0.743, 0.023], loss: 8.281302, mean_squared_error: 2208.014160, mean_q: -57.121113\n",
      " 92086/100000: episode: 461, duration: 2.565s, episode steps: 200, steps per second: 78, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.220 [0.000, 2.000], mean observation: -0.259 [-0.972, 0.027], loss: 8.831310, mean_squared_error: 2189.395264, mean_q: -56.926704\n",
      " 92286/100000: episode: 462, duration: 2.761s, episode steps: 200, steps per second: 72, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.205 [0.000, 2.000], mean observation: -0.266 [-1.189, 0.094], loss: 7.280838, mean_squared_error: 2217.267090, mean_q: -57.232822\n",
      " 92486/100000: episode: 463, duration: 2.061s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.970 [0.000, 2.000], mean observation: -0.251 [-1.049, 0.040], loss: 8.352265, mean_squared_error: 2237.353760, mean_q: -57.555721\n",
      " 92686/100000: episode: 464, duration: 2.065s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.975 [0.000, 2.000], mean observation: -0.252 [-0.812, 0.035], loss: 8.004765, mean_squared_error: 2239.485352, mean_q: -57.615833\n",
      " 92886/100000: episode: 465, duration: 2.186s, episode steps: 200, steps per second: 91, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.160 [0.000, 2.000], mean observation: -0.236 [-0.745, 0.025], loss: 8.361572, mean_squared_error: 2259.943115, mean_q: -57.792686\n",
      " 93086/100000: episode: 466, duration: 1.976s, episode steps: 200, steps per second: 101, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.130 [0.000, 2.000], mean observation: -0.259 [-0.806, 0.034], loss: 7.845173, mean_squared_error: 2280.242920, mean_q: -58.103371\n",
      " 93286/100000: episode: 467, duration: 2.185s, episode steps: 200, steps per second: 92, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.705 [0.000, 2.000], mean observation: -0.287 [-1.127, 0.043], loss: 9.226932, mean_squared_error: 2278.692871, mean_q: -58.037128\n",
      " 93486/100000: episode: 468, duration: 2.579s, episode steps: 200, steps per second: 78, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.975 [0.000, 2.000], mean observation: -0.250 [-0.931, 0.030], loss: 8.870664, mean_squared_error: 2288.539062, mean_q: -58.268368\n",
      " 93686/100000: episode: 469, duration: 2.400s, episode steps: 200, steps per second: 83, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.715 [0.000, 2.000], mean observation: -0.302 [-1.159, 0.041], loss: 8.718006, mean_squared_error: 2274.816650, mean_q: -58.043644\n",
      " 93886/100000: episode: 470, duration: 2.503s, episode steps: 200, steps per second: 80, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.840 [0.000, 2.000], mean observation: -0.286 [-0.954, 0.034], loss: 9.189508, mean_squared_error: 2243.675049, mean_q: -57.524338\n",
      " 94086/100000: episode: 471, duration: 2.255s, episode steps: 200, steps per second: 89, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.245 [0.000, 2.000], mean observation: -0.233 [-1.025, 0.073], loss: 8.487871, mean_squared_error: 2255.518799, mean_q: -57.823605\n",
      " 94286/100000: episode: 472, duration: 2.199s, episode steps: 200, steps per second: 91, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.045 [0.000, 2.000], mean observation: -0.251 [-0.758, 0.026], loss: 8.920984, mean_squared_error: 2263.280518, mean_q: -57.845760\n",
      " 94486/100000: episode: 473, duration: 2.112s, episode steps: 200, steps per second: 95, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.950 [0.000, 2.000], mean observation: -0.234 [-1.200, 0.107], loss: 8.379119, mean_squared_error: 2275.831055, mean_q: -58.067348\n",
      " 94686/100000: episode: 474, duration: 2.057s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.920 [0.000, 2.000], mean observation: -0.273 [-0.914, 0.040], loss: 7.503330, mean_squared_error: 2268.240967, mean_q: -57.960217\n",
      " 94886/100000: episode: 475, duration: 2.170s, episode steps: 200, steps per second: 92, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.910 [0.000, 2.000], mean observation: -0.257 [-0.950, 0.042], loss: 5.663690, mean_squared_error: 2355.274902, mean_q: -59.169327\n",
      " 95086/100000: episode: 476, duration: 2.305s, episode steps: 200, steps per second: 87, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.850 [0.000, 2.000], mean observation: -0.260 [-1.183, 0.140], loss: 9.540623, mean_squared_error: 2359.132568, mean_q: -59.102341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95286/100000: episode: 477, duration: 2.165s, episode steps: 200, steps per second: 92, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.000 [0.000, 2.000], mean observation: -0.268 [-0.869, 0.029], loss: 10.590961, mean_squared_error: 2356.095215, mean_q: -59.004627\n",
      " 95486/100000: episode: 478, duration: 2.027s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.205 [0.000, 2.000], mean observation: -0.254 [-0.769, 0.022], loss: 7.796537, mean_squared_error: 2341.018799, mean_q: -58.932598\n",
      " 95686/100000: episode: 479, duration: 2.048s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.005 [0.000, 2.000], mean observation: -0.265 [-0.861, 0.037], loss: 9.761810, mean_squared_error: 2351.528809, mean_q: -59.009384\n",
      " 95886/100000: episode: 480, duration: 2.115s, episode steps: 200, steps per second: 95, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.995 [0.000, 2.000], mean observation: -0.258 [-0.701, 0.015], loss: 7.391772, mean_squared_error: 2363.364258, mean_q: -59.244122\n",
      " 96086/100000: episode: 481, duration: 2.029s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.815 [0.000, 2.000], mean observation: -0.234 [-1.061, 0.290], loss: 6.925461, mean_squared_error: 2407.737793, mean_q: -59.751709\n",
      " 96286/100000: episode: 482, duration: 2.051s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.010 [0.000, 2.000], mean observation: -0.264 [-0.763, 0.031], loss: 8.388932, mean_squared_error: 2421.894775, mean_q: -59.912167\n",
      " 96486/100000: episode: 483, duration: 2.015s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.940 [0.000, 2.000], mean observation: -0.261 [-0.691, 0.019], loss: 8.737897, mean_squared_error: 2433.991455, mean_q: -60.063042\n",
      " 96686/100000: episode: 484, duration: 2.098s, episode steps: 200, steps per second: 95, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.195 [0.000, 2.000], mean observation: -0.258 [-0.835, 0.026], loss: 8.153545, mean_squared_error: 2373.474854, mean_q: -59.244228\n",
      " 96886/100000: episode: 485, duration: 2.044s, episode steps: 200, steps per second: 98, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.085 [0.000, 2.000], mean observation: -0.257 [-0.769, 0.021], loss: 6.213164, mean_squared_error: 2444.222168, mean_q: -60.215694\n",
      " 97086/100000: episode: 486, duration: 2.010s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.225 [0.000, 2.000], mean observation: -0.245 [-0.786, 0.030], loss: 11.552608, mean_squared_error: 2410.553955, mean_q: -59.650928\n",
      " 97286/100000: episode: 487, duration: 1.995s, episode steps: 200, steps per second: 100, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.135 [0.000, 2.000], mean observation: -0.256 [-0.793, 0.023], loss: 9.039379, mean_squared_error: 2377.306152, mean_q: -59.394726\n",
      " 97486/100000: episode: 488, duration: 2.028s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.065 [0.000, 2.000], mean observation: -0.233 [-1.043, 0.204], loss: 8.566867, mean_squared_error: 2388.269775, mean_q: -59.498085\n",
      " 97686/100000: episode: 489, duration: 2.060s, episode steps: 200, steps per second: 97, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.355 [0.000, 2.000], mean observation: -0.243 [-0.609, 0.016], loss: 5.591130, mean_squared_error: 2410.737793, mean_q: -59.814228\n",
      " 97886/100000: episode: 490, duration: 2.144s, episode steps: 200, steps per second: 93, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.045 [0.000, 2.000], mean observation: -0.252 [-0.952, 0.029], loss: 11.818615, mean_squared_error: 2350.387695, mean_q: -58.880684\n",
      " 98086/100000: episode: 491, duration: 2.539s, episode steps: 200, steps per second: 79, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.775 [0.000, 2.000], mean observation: -0.272 [-0.902, 0.040], loss: 9.886701, mean_squared_error: 2265.323975, mean_q: -57.866417\n",
      " 98286/100000: episode: 492, duration: 2.464s, episode steps: 200, steps per second: 81, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.955 [0.000, 2.000], mean observation: -0.285 [-1.013, 0.041], loss: 8.670811, mean_squared_error: 2230.892090, mean_q: -57.475166\n",
      " 98486/100000: episode: 493, duration: 2.030s, episode steps: 200, steps per second: 99, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.985 [0.000, 2.000], mean observation: -0.262 [-0.685, 0.015], loss: 8.390006, mean_squared_error: 2264.994141, mean_q: -57.909500\n",
      " 98686/100000: episode: 494, duration: 2.117s, episode steps: 200, steps per second: 94, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.200 [0.000, 2.000], mean observation: -0.238 [-0.874, 0.040], loss: 8.098098, mean_squared_error: 2256.928467, mean_q: -57.868065\n",
      " 98886/100000: episode: 495, duration: 2.219s, episode steps: 200, steps per second: 90, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.245 [0.000, 2.000], mean observation: -0.242 [-0.761, 0.022], loss: 8.044233, mean_squared_error: 2267.099365, mean_q: -57.961170\n",
      " 99086/100000: episode: 496, duration: 2.328s, episode steps: 200, steps per second: 86, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.050 [0.000, 2.000], mean observation: -0.258 [-0.749, 0.024], loss: 6.522978, mean_squared_error: 2300.148438, mean_q: -58.417446\n",
      " 99286/100000: episode: 497, duration: 2.456s, episode steps: 200, steps per second: 81, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.870 [0.000, 2.000], mean observation: -0.274 [-0.929, 0.040], loss: 10.032568, mean_squared_error: 2306.600586, mean_q: -58.388729\n",
      " 99486/100000: episode: 498, duration: 2.915s, episode steps: 200, steps per second: 69, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.935 [0.000, 2.000], mean observation: -0.275 [-1.016, 0.038], loss: 7.455094, mean_squared_error: 2285.612793, mean_q: -58.149601\n",
      " 99686/100000: episode: 499, duration: 2.575s, episode steps: 200, steps per second: 78, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 0.890 [0.000, 2.000], mean observation: -0.301 [-1.171, 0.040], loss: 7.888249, mean_squared_error: 2334.365967, mean_q: -58.760494\n",
      " 99886/100000: episode: 500, duration: 2.600s, episode steps: 200, steps per second: 77, episode reward: -200.000, mean reward: -1.000 [-1.000, -1.000], mean action: 1.005 [0.000, 2.000], mean observation: -0.259 [-0.780, 0.025], loss: 8.080182, mean_squared_error: 2357.497314, mean_q: -59.158310\n",
      "done, took 1033.369 seconds\n"
     ]
    }
   ],
   "source": [
    "hist = dqn.fit(env, nb_steps=100000, visualize=False, verbose=2)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.render(close=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: -200.000, steps: 200\n"
     ]
    }
   ],
   "source": [
    "dqn.test(env, nb_episodes=5, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28aab5b8cc0>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n448AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28aaa8e6198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot(111)\n",
    "ax.plot(hist.history.get('episode_reward'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
